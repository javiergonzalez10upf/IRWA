{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxCxZQwIBsCM"
      },
      "source": [
        "**FINAL PROJECT PART 3: Ranking**\n",
        "\n",
        "- Iria Quintero (254373)\n",
        "- Javier González (243078)\n",
        "- Mireia Pou (251725)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtkiMQfb-87U"
      },
      "source": [
        "# Imports, Drive and previous practices (necessary functions only)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eG-Dlwm7X_oV"
      },
      "source": [
        "## Part 0: Imports and Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgPNXbg6JHNz"
      },
      "outputs": [],
      "source": [
        "#!pip install wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff_LvmJ6rkWA",
        "outputId": "74fd0e4d-3353-462a-d2ac-8ce40fe0af3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet') # Download the wordnet dataset\n",
        "\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import FreqDist\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from numpy import linalg as la\n",
        "\n",
        "from collections import Counter\n",
        "import itertools\n",
        "import networkx as nx\n",
        "from datetime import datetime\n",
        "\n",
        "from collections import defaultdict\n",
        "import time\n",
        "from array import array\n",
        "import collections\n",
        "\n",
        "import zipfile\n",
        "import json\n",
        "\n",
        "import csv\n",
        "import string\n",
        "import re\n",
        "import math\n",
        "\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import gensim\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Load the embedding model (BERT)\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')  # Use a lightweight model for speed\n",
        "\n",
        "# Load necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load a pre-trained NER model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "#doc2vec\n",
        "from gensim.models import Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJI_Z-Vn6b6v",
        "outputId": "3f3904d1-f54f-40c3-ae45-08c87772ece4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrUw-B9TYFPS"
      },
      "source": [
        "## Part 1: Data load, data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deM8jzPr12qo",
        "outputId": "dfb01d99-0838-4628-fff7-76fb3b8f1e59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of JSON objects loaded: 117407\n",
            "Sample JSON object:\n",
            "{'url': 'https://twitter.com/ArjunSinghPanam/status/1364506249291784198', 'date': '2021-02-24T09:23:35+00:00', 'content': 'The world progresses while the Indian police and Govt are still trying to take India back to the horrific past through its tyranny. \\n\\n@narendramodi @DelhiPolice Shame on you. \\n\\n#ModiDontSellFarmers \\n#FarmersProtest \\n#FreeNodeepKaur https://t.co/es3kn0IQAF', 'renderedContent': 'The world progresses while the Indian police and Govt are still trying to take India back to the horrific past through its tyranny. \\n\\n@narendramodi @DelhiPolice Shame on you. \\n\\n#ModiDontSellFarmers \\n#FarmersProtest \\n#FreeNodeepKaur twitter.com/ravisinghka/st…', 'id': 1364506249291784198, 'user': {'username': 'ArjunSinghPanam', 'displayname': 'Arjun Singh Panam', 'id': 45091142, 'description': 'Global Citizen, Actor, Director: Sky is the roof above my head, the world is the road I travel, love is my food & mother earth is my bed. Roy in @CosmosMovie', 'rawDescription': 'Global Citizen, Actor, Director: Sky is the roof above my head, the world is the road I travel, love is my food & mother earth is my bed. Roy in @CosmosMovie', 'descriptionUrls': [], 'verified': False, 'created': '2009-06-06T07:50:57+00:00', 'followersCount': 603, 'friendsCount': 311, 'statusesCount': 17534, 'favouritesCount': 4269, 'listedCount': 23, 'mediaCount': 1211, 'location': '', 'protected': False, 'linkUrl': 'https://www.cosmosmovieofficial.com', 'linkTcourl': 'https://t.co/3uaoV3gCt3', 'profileImageUrl': 'https://pbs.twimg.com/profile_images/1215541746492461056/3De61YoQ_normal.jpg', 'profileBannerUrl': 'https://pbs.twimg.com/profile_banners/45091142/1612601766', 'url': 'https://twitter.com/ArjunSinghPanam'}, 'outlinks': ['https://twitter.com/ravisinghka/status/1364150844757860352'], 'tcooutlinks': ['https://t.co/es3kn0IQAF'], 'replyCount': 0, 'retweetCount': 0, 'likeCount': 0, 'quoteCount': 0, 'conversationId': 1364506249291784198, 'lang': 'en', 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>', 'sourceUrl': 'http://twitter.com/download/iphone', 'sourceLabel': 'Twitter for iPhone', 'media': None, 'retweetedTweet': None, 'quotedTweet': {'url': 'https://twitter.com/RaviSinghKA/status/1364150844757860352', 'date': '2021-02-23T09:51:20+00:00', 'content': 'This is what the indian police are good at, beating &amp; raping women ! @police_haryana @DelhiPolice \\n\\nhttps://t.co/mj1qzF7nGh', 'renderedContent': 'This is what the indian police are good at, beating &amp; raping women ! @police_haryana @DelhiPolice \\n\\ngoogle.co.uk/amp/s/m.timeso…', 'id': 1364150844757860352, 'user': {'username': 'RaviSinghKA', 'displayname': 'ravinder singh', 'id': 2347762888, 'description': 'Founder/CEO of Khalsa Aid, Sikh,philanthropist, 20 Years of coordinating aid,humanitarian & passionate about human rights.All views my own:Inc working in Iraq', 'rawDescription': 'Founder/CEO of Khalsa Aid, Sikh,philanthropist, 20 Years of coordinating aid,humanitarian & passionate about human rights.All views my own:Inc working in Iraq', 'descriptionUrls': [], 'verified': False, 'created': '2014-02-16T23:38:54+00:00', 'followersCount': 227423, 'friendsCount': 4042, 'statusesCount': 38683, 'favouritesCount': 30134, 'listedCount': 212, 'mediaCount': 4944, 'location': 'Slough, England ', 'protected': False, 'linkUrl': 'http://www.khalsaaid.org', 'linkTcourl': 'https://t.co/cgdi8BLkK2', 'profileImageUrl': 'https://pbs.twimg.com/profile_images/686526444642643968/bnCPdE7N_normal.jpg', 'profileBannerUrl': 'https://pbs.twimg.com/profile_banners/2347762888/1591307489', 'url': 'https://twitter.com/RaviSinghKA'}, 'outlinks': ['https://www.google.co.uk/amp/s/m.timesofindia.com/city/chandigarh/was-brutally-thrashed-in-thana-nodeep-kaur-tells-punjab-and-haryana-high-court/amp_articleshow/81164092.cms'], 'tcooutlinks': ['https://t.co/mj1qzF7nGh'], 'replyCount': 66, 'retweetCount': 744, 'likeCount': 1939, 'quoteCount': 59, 'conversationId': 1364150844757860352, 'lang': 'en', 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>', 'sourceUrl': 'http://twitter.com/download/iphone', 'sourceLabel': 'Twitter for iPhone', 'media': None, 'retweetedTweet': None, 'quotedTweet': None, 'mentionedUsers': [{'username': 'police_haryana', 'displayname': 'Haryana Police', 'id': 887564756629966848, 'description': None, 'rawDescription': None, 'descriptionUrls': None, 'verified': None, 'created': None, 'followersCount': None, 'friendsCount': None, 'statusesCount': None, 'favouritesCount': None, 'listedCount': None, 'mediaCount': None, 'location': None, 'protected': None, 'linkUrl': None, 'linkTcourl': None, 'profileImageUrl': None, 'profileBannerUrl': None, 'url': 'https://twitter.com/police_haryana'}, {'username': 'DelhiPolice', 'displayname': '#DilKiPolice Delhi Police', 'id': 1850705408, 'description': None, 'rawDescription': None, 'descriptionUrls': None, 'verified': None, 'created': None, 'followersCount': None, 'friendsCount': None, 'statusesCount': None, 'favouritesCount': None, 'listedCount': None, 'mediaCount': None, 'location': None, 'protected': None, 'linkUrl': None, 'linkTcourl': None, 'profileImageUrl': None, 'profileBannerUrl': None, 'url': 'https://twitter.com/DelhiPolice'}]}, 'mentionedUsers': [{'username': 'narendramodi', 'displayname': 'Narendra Modi', 'id': 18839785, 'description': None, 'rawDescription': None, 'descriptionUrls': None, 'verified': None, 'created': None, 'followersCount': None, 'friendsCount': None, 'statusesCount': None, 'favouritesCount': None, 'listedCount': None, 'mediaCount': None, 'location': None, 'protected': None, 'linkUrl': None, 'linkTcourl': None, 'profileImageUrl': None, 'profileBannerUrl': None, 'url': 'https://twitter.com/narendramodi'}, {'username': 'DelhiPolice', 'displayname': '#DilKiPolice Delhi Police', 'id': 1850705408, 'description': None, 'rawDescription': None, 'descriptionUrls': None, 'verified': None, 'created': None, 'followersCount': None, 'friendsCount': None, 'statusesCount': None, 'favouritesCount': None, 'listedCount': None, 'mediaCount': None, 'location': None, 'protected': None, 'linkUrl': None, 'linkTcourl': None, 'profileImageUrl': None, 'profileBannerUrl': None, 'url': 'https://twitter.com/DelhiPolice'}]}\n"
          ]
        }
      ],
      "source": [
        "# Charging json data to variable data\n",
        "# Specify name and path of .zip\n",
        "zip_path = '/content/drive/Shareddrives/IRWA/Project/data/data.zip' #Change path to your own settings\n",
        "\n",
        "# Open .zip\n",
        "with zipfile.ZipFile(zip_path) as z:\n",
        "    # Read JSON from .zip line by line\n",
        "    with z.open('data/farmers-protest-tweets.json') as f:\n",
        "        data = []  # Initialize an empty list to store the JSON objects\n",
        "        for line in f:\n",
        "            try:\n",
        "                # Attempt to parse each line as a JSON object\n",
        "                json_obj = json.loads(line)\n",
        "                data.append(json_obj)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Skipping invalid line: {line} due to error: {e}\")  # Print error and skip invalid lines\n",
        "\n",
        "\n",
        "#Show JSON by printing a sample\n",
        "print(f\"Number of JSON objects loaded: {len(data)}\")\n",
        "if data:\n",
        "    print(\"Sample JSON object:\")\n",
        "    print(data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZecZV0_5SSV"
      },
      "source": [
        "Function to read the doc id to tweet id map file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "132kfd6y5Y7k"
      },
      "outputs": [],
      "source": [
        "def load_docid_map_from_zip(zip_file_path, csv_file_name):\n",
        "    docid_map = {}\n",
        "    with zipfile.ZipFile(zip_file_path) as z:\n",
        "        with z.open(csv_file_name) as file:\n",
        "            reader = csv.DictReader(file.read().decode('utf-8').splitlines())  # Decode and read the lines\n",
        "            for row in reader:\n",
        "                docid_map[row['id']] = row['docId']  # Map 'id' to 'docId'\n",
        "    return docid_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "G30Rmdbu7fN_"
      },
      "outputs": [],
      "source": [
        "docid_map = load_docid_map_from_zip(zip_path, 'data/tweet_document_ids_map.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CK9fff4f4FSt"
      },
      "outputs": [],
      "source": [
        "def build_terms(line):\n",
        "    \"\"\"\n",
        "    Preprocess the text by removing stop words, stemming,\n",
        "    transforming to lowercase, removing hashtags, and returning tokens.\n",
        "\n",
        "    Argument:\n",
        "    line -- string (text) to be preprocessed\n",
        "\n",
        "    Returns:\n",
        "    line - a list of tokens corresponding to the input text after the preprocessing\n",
        "    \"\"\"\n",
        "\n",
        "    stemmer = PorterStemmer()\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "    # Start preprocessing\n",
        "    line = line.lower()  # Convert to lowercase\n",
        "\n",
        "    #remove hashtags (before tokenization)\n",
        "    line = re.sub(r'#\\w+', '', line)\n",
        "\n",
        "    line = re.sub(r'[^a-z0-9\\s]', '', line)  # Remove every symbol that is not a letter or a number\n",
        "    line = line.split()  # Tokenize the text to get a list of terms\n",
        "\n",
        "    # Remove punctuation\n",
        "    line = [word.translate(str.maketrans('', '', string.punctuation)) for word in line]\n",
        "    line = [item for item in line if item not in stop_words]  # Remove stopwords\n",
        "    line = [word for word in line if len(word) > 1]  # Remove single-letter words\n",
        "    line = [stemmer.stem(word) for word in line]  # Stemming\n",
        "\n",
        "\n",
        "    return line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhnTbyLFEoMG"
      },
      "source": [
        "Function to get DocID | TweetID | Tweet Content | Tokenized Tweet | Date | Hashtags | Likes | Retweets | Url from a json tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "44BmozJC8Ixe"
      },
      "outputs": [],
      "source": [
        "def extract_tweet_info_with_docid(tweet_json, docid_map):\n",
        "    # Extract the same fields as before\n",
        "    tweet_id = tweet_json.get('id', '')\n",
        "    doc_id = docid_map.get(str(tweet_id))  # Use str(tweet_id) to ensure proper matching\n",
        "\n",
        "    if not doc_id:\n",
        "        return None\n",
        "\n",
        "    original_content = tweet_json.get('content', '')\n",
        "    tokenized_content = build_terms(original_content)  # Apply text preprocessing\n",
        "    tweet_date = tweet_json.get('date', '')\n",
        "\n",
        "    hashtags = re.findall(r'#\\w+', original_content)\n",
        "    hashtags = [re.sub(r'#', '', hashtag) for hashtag in hashtags]\n",
        "    hashtags = [build_terms(hashtag) for hashtag in hashtags]\n",
        "    hashtags = [item for sublist in hashtags for item in sublist]\n",
        "    tweet_likes = tweet_json.get('likeCount', 0)\n",
        "    tweet_retweets = tweet_json.get('retweetCount', 0)\n",
        "    reply_count = tweet_json.get('replyCount', 0)\n",
        "    tweet_url = tweet_json.get('url', '')\n",
        "\n",
        "    # Extract user information (username and follower count)\n",
        "    user_info = tweet_json.get('user', {})\n",
        "    username = user_info.get('username', 'unknown')\n",
        "    followers_count = user_info.get('followersCount', 0)\n",
        "\n",
        "    # Return the extracted information as a dictionary\n",
        "    return {\n",
        "        'DocID': doc_id,\n",
        "        'TweetID': tweet_id,\n",
        "        'Original Tweet': original_content,\n",
        "        'Tokenized Tweet': tokenized_content,\n",
        "        'Date': tweet_date,\n",
        "        'Username': username,           # Twitter username\n",
        "        'FollowersCount': followers_count,  # Number of followers\n",
        "        'Hashtags': hashtags,\n",
        "        'Likes': tweet_likes,\n",
        "        'Retweets': tweet_retweets,\n",
        "        'ReplyCount': reply_count,\n",
        "        'Url': tweet_url\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US64D3p-5QWH",
        "outputId": "7399c29a-6f71-478f-ccf9-41c18ede7919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of JSON objects processed: 48429\n",
            "Sample processed data:\n",
            "{'DocID': 'doc_0', 'TweetID': 1364506249291784198, 'Original Tweet': 'The world progresses while the Indian police and Govt are still trying to take India back to the horrific past through its tyranny. \\n\\n@narendramodi @DelhiPolice Shame on you. \\n\\n#ModiDontSellFarmers \\n#FarmersProtest \\n#FreeNodeepKaur https://t.co/es3kn0IQAF', 'Tokenized Tweet': ['world', 'progress', 'indian', 'polic', 'govt', 'still', 'tri', 'take', 'india', 'back', 'horrif', 'past', 'tyranni', 'narendramodi', 'delhipolic', 'shame', 'httpstcoes3kn0iqaf'], 'Date': '2021-02-24T09:23:35+00:00', 'Username': 'ArjunSinghPanam', 'FollowersCount': 603, 'Hashtags': ['modidontsellfarm', 'farmersprotest', 'freenodeepkaur'], 'Likes': 0, 'Retweets': 0, 'ReplyCount': 0, 'Url': 'https://twitter.com/ArjunSinghPanam/status/1364506249291784198'}\n"
          ]
        }
      ],
      "source": [
        "processed_data = []\n",
        "\n",
        "for json_obj in data:\n",
        "    # Create a copy of JSON original object\n",
        "    processed_obj = json_obj.copy()  # Copia todos los campos del objeto JSON original\n",
        "\n",
        "    # Check if content is in the object\n",
        "    if 'content' in processed_obj:\n",
        "        # Extraer información necesaria\n",
        "        processed_obj = extract_tweet_info_with_docid(processed_obj, docid_map)\n",
        "\n",
        "    # Add the processed object to the list if is not none\n",
        "    if processed_obj is not None:\n",
        "        processed_data.append(processed_obj)\n",
        "\n",
        "# Shows a sample of the processed data\n",
        "print(f\"Number of JSON objects processed: {len(processed_data)}\")\n",
        "if processed_data:\n",
        "    print(\"Sample processed data:\")\n",
        "    print(processed_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buz8u4HoYMiV"
      },
      "source": [
        "# Part 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pousqpDYYQjt"
      },
      "source": [
        "## 3.1. Ranking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4USprVIMYT0O"
      },
      "source": [
        "### 3.1.1. TF-IDF + cosine similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9JAQj8ZZVyc"
      },
      "source": [
        "To rank with tf-idf, we first need to create the index and then proceed to rank."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "I-UHg8VsYL-X"
      },
      "outputs": [],
      "source": [
        "def create_index_tfidf(processed_data):\n",
        "    \"\"\"\n",
        "    Implement the inverted index and compute tf, df, and idf for a collection of tweets.\n",
        "\n",
        "    Returns:\n",
        "    index - the inverted index containing terms as keys and the corresponding\n",
        "            list of documents these keys appear in (and the positions) as values.\n",
        "    tf - normalized term frequency for each term in each document\n",
        "    df - number of documents each term appears in\n",
        "    idf - inverse document frequency of each term\n",
        "    tweet_content_index - mapping of DocID to the original tweet content\n",
        "    \"\"\"\n",
        "\n",
        "    index = defaultdict(list)\n",
        "    tf = defaultdict(list)  # Term frequencies of terms in documents\n",
        "    df = defaultdict(int)  # Document frequencies of terms in the corpus\n",
        "    tweet_content_index = defaultdict(str)  # Index for original tweet content\n",
        "    num_documents = len(processed_data)  # Total number of documents (tweets)\n",
        "\n",
        "    for tweet in processed_data:\n",
        "        doc_id = tweet['DocID']\n",
        "        terms = tweet['Tokenized Tweet']  # List of terms (already tokenized)\n",
        "        original_tweet = tweet['Original Tweet']\n",
        "\n",
        "        ## Build the current tweet index for TF normalization and document frequency\n",
        "        current_tweet_index = {}\n",
        "\n",
        "        for position, term in enumerate(terms):  # Terms from the tokenized tweet\n",
        "            if term not in current_tweet_index:\n",
        "                current_tweet_index[term] = [doc_id, array('I', [position])] # this is an entry\n",
        "            else:\n",
        "                current_tweet_index[term][1].append(position)\n",
        "\n",
        "        # Normalize term frequencies\n",
        "        norm = 0\n",
        "        for entry in current_tweet_index.values():\n",
        "            norm += len(entry[1]) ** 2\n",
        "        norm = math.sqrt(norm)\n",
        "\n",
        "        # Calculate TF and DF weights\n",
        "        for term, entry in current_tweet_index.items():\n",
        "            tf[term].append(np.round(len(entry[1]) / norm, 4))  # TF calculation\n",
        "            df[term] += 1  # Increment DF for current term\n",
        "\n",
        "            # Merge the current tweet index with the main index\n",
        "            index[term].append(entry)\n",
        "\n",
        "    # Compute IDF following the formula\n",
        "    idf = {}\n",
        "    for term in df:\n",
        "        idf[term] = np.round(np.log(float(num_documents) / df[term]), 4)\n",
        "\n",
        "    return index, tf, df, idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlQA028_ZnYZ",
        "outputId": "666389c7-24e5-4ce9-ba53-ae9fe4ff9738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time to create the TF-IDF index: 9.63 seconds\n"
          ]
        }
      ],
      "source": [
        "# Create index\n",
        "start_time = time.time()\n",
        "index, tf, df, idf = create_index_tfidf(processed_data)\n",
        "print(\"Total time to create the TF-IDF index: {} seconds\" .format(np.round(time.time() - start_time, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ikci3gR8Zvau"
      },
      "source": [
        "Now we have the index and the tf-idf, we can proceed to ranking:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "c-3RZ-jUZnre"
      },
      "outputs": [],
      "source": [
        "def rank_documents(terms, docs, index, idf, tf):\n",
        "    \"\"\"\n",
        "    Perform the ranking of the results of a search based on the tf-idf weights\n",
        "\n",
        "    Argument:\n",
        "    terms -- list of query terms\n",
        "    docs -- list of documents, to rank, matching the query\n",
        "    index -- inverted index data structure\n",
        "    idf -- inverted document frequencies\n",
        "    tf -- term frequencies\n",
        "\n",
        "    Returns:\n",
        "    Print the list of ranked documents\n",
        "    \"\"\"\n",
        "    doc_vectors = defaultdict(lambda: [0] * len(terms))\n",
        "    query_vector = [0] * len(terms)\n",
        "\n",
        "    # Compute the norm for the query tf\n",
        "    query_terms_count = collections.Counter(terms)\n",
        "    query_norm = la.norm(list(query_terms_count.values()))\n",
        "\n",
        "    for termIndex, term in enumerate(terms):\n",
        "        if term not in index:\n",
        "            continue\n",
        "\n",
        "        # Compute tf*idf (normalize TF as done with documents)\n",
        "        query_vector[termIndex]= query_terms_count[term]/query_norm * idf[term]\n",
        "\n",
        "        # Generate doc_vectors for matching docs\n",
        "        for doc_index, entry in enumerate(index[term]):\n",
        "            doc, postings = entry\n",
        "\n",
        "            if doc in docs:\n",
        "                doc_vectors[doc][termIndex] = tf[term][doc_index] * idf[term]\n",
        "\n",
        "    # Calculate the score of each doc\n",
        "    # Compute the cosine similarity between queyVector and each docVector:\n",
        "\n",
        "    doc_scores=[[np.dot(curDocVec, query_vector), doc] for doc, curDocVec in doc_vectors.items() ]\n",
        "    doc_scores.sort(reverse=True)\n",
        "    result_docs = [x[1] for x in doc_scores]\n",
        "\n",
        "    #print document titles instead if document id's\n",
        "    #result_docs=[ title_index[x] for x in result_docs ]\n",
        "\n",
        "    if len(result_docs) == 0:\n",
        "        print(\"No results found, try again\")\n",
        "        query = input()\n",
        "        docs = search_tf_idf(query, index)\n",
        "\n",
        "    return result_docs, doc_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "iXisXjpdZ4g2"
      },
      "outputs": [],
      "source": [
        "# Necessary function search in the ranking, searches queries that contains ALL the terms\n",
        "def search_tf_idf(query, index):\n",
        "    \"\"\"\n",
        "    Output is the list of documents that contain all of the query terms.\n",
        "    So, we will get the list of documents for each query term, and take the intersection of them.\n",
        "    \"\"\"\n",
        "    query = build_terms(query)\n",
        "    docs = None  # Start with None to allow initialization by the first term\n",
        "    for term in query:\n",
        "        try:\n",
        "            # Store in term_docs the ids of the docs that contain \"term\"\n",
        "            term_docs = set(posting[0] for posting in index[term])\n",
        "\n",
        "            if docs is None:\n",
        "                docs = term_docs  # Initialize with the first term's docs\n",
        "            else:\n",
        "                docs = docs.intersection(term_docs) # (AND operation)\n",
        "        except KeyError:\n",
        "            # If any term is not in the index, no documents contain all terms, return empty list\n",
        "            return []\n",
        "\n",
        "    # Convert docs to a list if it's not empty\n",
        "    docs = list(docs)\n",
        "\n",
        "    #Rank the resulting documents\n",
        "    ranked_docs, doc_scores = rank_documents(query, docs, index, idf, tf)\n",
        "    return ranked_docs, doc_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyanPEn7aThe",
        "outputId": "3bb00484-ce8a-438c-adcf-a68efa46adce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert your query (i.e.: Disha Ravi):\n",
            "\n",
            "Disha Ravi\n",
            "\n",
            "======================\n",
            "Top 10 results out of 628 ranked documents for the searched query:\n",
            "\n",
            "----------------------\n",
            "\n",
            "doc_id = doc_35225 \n",
            "doc_content = Free Disha Ravi \n",
            "\n",
            "#FarmersProtest  #IndiaBeingSilenced\n",
            "\n",
            "----------------------\n",
            "\n",
            "doc_id = doc_32205 \n",
            "doc_content = #IndiaBeingSilenced \n",
            "#farmersprotest \n",
            "Disha ravi https://t.co/OVmvJy3d8V\n",
            "\n",
            "----------------------\n",
            "\n",
            "doc_id = doc_28152 \n",
            "doc_content = I Stand With Disha Ravi \n",
            "#ReleaseDishaRavi \n",
            "#FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "doc_id = doc_15603 \n",
            "doc_content = #StandWithDishaRavi\n",
            "I stand with Disha Ravi\n",
            "#FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "doc_id = doc_11995 \n",
            "doc_content = #FarmersProtest. Disha Ravi. https://t.co/VbW9rYLUIa\n",
            "\n",
            "----------------------\n",
            "\n",
            "doc_id = doc_24045 \n",
            "doc_content = #releasedisha #ReleaseDishaRavi\n",
            "#DishaRavi #DishaAnnappaRavi\n",
            "#JusticeForDisha\n",
            "#JusticeForDisha\n",
            "#FarmersProtest\n",
            "\n",
            "Her Name Is Disha Ravi, Not Disha Ravi Joseph: Friends Rubbish Fake Claim\n",
            "\n",
            "https://t.co/Gb9nkYpH0x\n",
            "\n",
            "----------------------\n",
            "\n",
            "doc_id = doc_9719 \n",
            "doc_content = #FarmersProtest\n",
            "#MSPLawForAllCrops \n",
            "I stand with Disha Ravi https://t.co/znHFMvSNqn\n",
            "\n",
            "----------------------\n",
            "\n",
            "doc_id = doc_36255 \n",
            "doc_content = #JusticeForDisha\n",
            "Justice For Disha Ravi \n",
            "#FarmersProtest https://t.co/juR4gPo496\n",
            "\n",
            "----------------------\n",
            "\n",
            "doc_id = doc_36249 \n",
            "doc_content = #JusticeForDisha\n",
            "Justice For Disha Ravi \n",
            "#FarmersProtest https://t.co/YB0g4AngmY\n",
            "\n",
            "----------------------\n",
            "\n",
            "doc_id = doc_36243 \n",
            "doc_content = #ReleaseDishaRavi\n",
            "Justice For Disha Ravi \n",
            "#FarmersProtest https://t.co/Q8zY9sCDxu\n"
          ]
        }
      ],
      "source": [
        "# Try the function!\n",
        "print(\"Insert your query (i.e.: Disha Ravi):\\n\")\n",
        "query = input()\n",
        "docs, score = search_tf_idf(query, index)\n",
        "top = 10\n",
        "\n",
        "print(\"\\n======================\\nTop {} results out of {} ranked documents for the searched query:\".format(top, len(docs)))\n",
        "for d_id in docs[:top]:\n",
        "    tweet_info = next((tweet for tweet in processed_data if tweet['DocID'] == d_id), None)\n",
        "\n",
        "    if tweet_info:\n",
        "        # Print the original content of the tweet\n",
        "        print(\"\\n----------------------\\n\")\n",
        "        print(\"doc_id = {} \\ndoc_content = {}\".format(d_id, tweet_info['Original Tweet']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSxTykzdYXF7"
      },
      "source": [
        "### 3.1.2. Our score + cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "2A339RceYauC"
      },
      "outputs": [],
      "source": [
        "def rank_documents_personalized_with_context(terms, docs, index, idf, tf, processed_data):\n",
        "    \"\"\"\n",
        "    Rank documents by combining TF-IDF, popularity metrics, hashtag boost, and contextual similarity.\n",
        "\n",
        "    Parameters:\n",
        "    - terms: list of original query terms and expanded synonyms\n",
        "    - docs: list of document IDs to rank\n",
        "    - index: inverted index data structure\n",
        "    - idf: inverse document frequencies\n",
        "    - tf: term frequencies\n",
        "    - processed_data: list of tweet data including popularity metrics\n",
        "    - context_weight: weight for contextual similarity\n",
        "\n",
        "    Returns:\n",
        "    - Ranked documents and their scores.\n",
        "    \"\"\"\n",
        "    # Initialize document vectors and query vector\n",
        "    doc_vectors = defaultdict(lambda: [0] * len(terms))\n",
        "    query_vector = [0] * len(terms)\n",
        "\n",
        "    '''\n",
        "    # Preprocess terms: separate original terms and synonyms\n",
        "    original_terms = set(build_terms(\" \".join(terms)))  # Assume first terms are original\n",
        "    expanded_query_terms = expand_query_with_synonyms(\" \".join(original_terms))\n",
        "    '''\n",
        "\n",
        "    # Create the query vector with weighted TF-IDF values\n",
        "    query_terms_count = collections.Counter(terms)\n",
        "    query_norm = la.norm([query_terms_count[term] for term in terms])\n",
        "\n",
        "    # For every query term, obtain the tfidf for the query and document vectors\n",
        "    for termIndex, term in enumerate(terms):\n",
        "        if term not in index:\n",
        "            continue\n",
        "        query_vector[termIndex] = (query_terms_count[term] / query_norm * idf[term])\n",
        "\n",
        "        # Update document vectors\n",
        "        for doc_index, entry in enumerate(index[term]):\n",
        "            doc, postings = entry\n",
        "            if doc in docs:\n",
        "                doc_vectors[doc][termIndex] = tf[term][doc_index] * idf[term]\n",
        "\n",
        "    # Calculate cosine similarity and contextual similarity\n",
        "    doc_scores = []\n",
        "    query_embedding = model.encode(\" \".join(terms))\n",
        "\n",
        "    for doc, curDocVec in doc_vectors.items():\n",
        "        cosine_sim = np.dot(curDocVec, query_vector)\n",
        "\n",
        "        # Retrieve popularity metrics for the tweet\n",
        "        tweet_info = next((tweet for tweet in processed_data if tweet['DocID'] == doc), None)\n",
        "        if tweet_info:\n",
        "            retweet_score = tweet_info['Retweets'] * 0.4\n",
        "            like_score = tweet_info['Likes'] * 0.2\n",
        "            comment_score = tweet_info.get('Comments', 0) * 0.4\n",
        "            popularity_score = retweet_score + like_score + comment_score\n",
        "        else:\n",
        "            popularity_score = 0\n",
        "\n",
        "        # Hashtag boost for original terms\n",
        "        hashtag_boost = 1.2 if any(term in tweet_info['Hashtags'] for term in terms) else 1.0\n",
        "\n",
        "        # Calculate contextual similarity\n",
        "        doc_embedding = model.encode(tweet_info['Original Tweet'])\n",
        "        contextual_similarity = cosine_similarity([query_embedding], [doc_embedding])[0][0]\n",
        "\n",
        "\n",
        "        # Calculate the final score\n",
        "        combined_score = (cosine_sim + popularity_score) * hashtag_boost + contextual_similarity\n",
        "        doc_scores.append((combined_score, doc))\n",
        "\n",
        "    # Sort by combined score in descending order\n",
        "    doc_scores.sort(reverse=True, key=lambda x: x[0])\n",
        "    ranked_docs = [x[1] for x in doc_scores]\n",
        "\n",
        "    return ranked_docs, doc_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "T9YSsAURQBZa"
      },
      "outputs": [],
      "source": [
        "def search_personalized_with_context(query, index, idf, tf, processed_data):\n",
        "    \"\"\"\n",
        "    Search for documents that contain all query terms and rank them based on personalized and contextual criteria.\n",
        "\n",
        "    Parameters:\n",
        "    - query: the search query string\n",
        "    - index: inverted index data structure\n",
        "    - idf: inverse document frequencies\n",
        "    - tf: term frequencies\n",
        "    - processed_data: list of tweet data including popularity metrics\n",
        "\n",
        "    Returns:\n",
        "    - Ranked documents and their scores.\n",
        "    \"\"\"\n",
        "    # Query terms\n",
        "    terms = build_terms(query)\n",
        "\n",
        "    # Collect documents containing any expanded query terms\n",
        "    docs = set()\n",
        "    for term in terms:\n",
        "        if term in index:\n",
        "            term_docs = set(posting[0] for posting in index[term])\n",
        "            docs.update(term_docs)\n",
        "\n",
        "    # Rank the resulting documents using the personalized ranking with context\n",
        "    ranked_docs, doc_scores = rank_documents_personalized_with_context(\n",
        "        terms, list(docs), index, idf, tf, processed_data\n",
        "    )\n",
        "    return ranked_docs, doc_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMnn6H26QoBl",
        "outputId": "ae40cabe-7707-4add-e052-9c393893a161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert your query (e.g., 'Disha Ravi'):\n",
            "\n",
            "Disha Ravi\n",
            "\n",
            "======================\n",
            "Top 10 results out of 829 ranked documents for the searched query:\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 1 | Score: 3672.0499\n",
            "doc_id = doc_38410 \n",
            "doc_content = disha ravi, a 21-year-old climate activist, has been arrested by delhi police for sharing a toolkit @GretaThunberg  posted in support of the #farmersprotest. \n",
            "\n",
            "disha’s arrest is alarming and the world needs to pay attention. #freedisharavi\n",
            "\n",
            "https://t.co/IYGsLpNjwZ\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 2 | Score: 3583.4351\n",
            "doc_id = doc_38012 \n",
            "doc_content = Disha Ravi broke down in court room and told judge that she had merely edited two lines in the toolkit and was supporting farmers. What is wrong in that? This is how this nation treats anyone who spreads awareness. #FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 3 | Score: 1183.9029\n",
            "doc_id = doc_37099 \n",
            "doc_content = Disha Ravi is 21 yrs\n",
            "\n",
            "A climate activist from India she campaigns for clean air, clean water and a liveable planet\n",
            "\n",
            "She is now facing state sanctioned violence for peacefully supporting farmers\n",
            "\n",
            "Silence is not an option we must all condemn this act of suppression\n",
            "\n",
            "#FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 4 | Score: 915.5114\n",
            "doc_id = doc_33861 \n",
            "doc_content = Disha Ravi is 21; a student &amp; climate activist\n",
            "\n",
            "Nodeep Kaur is 24; a labourer &amp;  Union activist\n",
            "\n",
            "Both women were targeted, arrested &amp; imprisoned for peacefully supporting the #FarmersProtest\n",
            "\n",
            "This suppression is driven by authoritarianism &amp; free market capitalism\n",
            "\n",
            "Don’t Be Silent\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 5 | Score: 787.4120\n",
            "doc_id = doc_31702 \n",
            "doc_content = Disha Ravi, a 21 yo climate activist, was arrested by Delhi Police for TWEETING in solidarity with the #FarmersProtest\n",
            "\n",
            "India is criminalizing dissent, free speech, &amp; expression - pillars of any democracy\n",
            "\n",
            "Calling on all leaders to DEMAND Disha's immediate release #FreeDishaRavi\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 6 | Score: 581.6552\n",
            "doc_id = doc_34869 \n",
            "doc_content = Indian and non indian friends: Disha Ravi is a 21 year old activist who was arrested for putting together a toolkit of links to donate to for the #FarmersProtest. Help us show the Indian government that we will not tolerate tyranny by tweeting the hashtag #ReleaseDishaRavi\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 7 | Score: 513.8689\n",
            "doc_id = doc_36881 \n",
            "doc_content = Dish Ravi is a 21-year-old climate justice activist.\n",
            "\n",
            "She tweeted an organizing toolkit in support of the #FarmersProtest\n",
            "\n",
            "In yet another move against free speech, the Delhi Police has arrested her. \n",
            "\n",
            "The Indian Government must #ReleaseDishaRavi now https://t.co/XtZT7slFjl\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 8 | Score: 426.7377\n",
            "doc_id = doc_38391 \n",
            "doc_content = the #farmersprotest is a climate justice movement. farmers are worried about ecological destruction &amp; want environmentally friendly practices. india is scared of the coalitions forming against these laws. disha’s arrest is a way to break this solidarity.\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 9 | Score: 392.2378\n",
            "doc_id = doc_38425 \n",
            "doc_content = #Verified              #FarmersProtest\n",
            "\n",
            "👉Delhi Police get 5 day custody of activist Disha Ravi\n",
            "\n",
            "👉She was arrested from Bangalore\n",
            "\n",
            "👉Police say, 'She was one of the Editors of the Toolkit Google Document'\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 10 | Score: 382.5017\n",
            "doc_id = doc_37376 \n",
            "doc_content = Indian #climate activist, Disha Ravi, aged 22, has been arrested after sharing a document intended to help farmers protest against new agricultural laws @fridays_india #FarmersProtest #FarmersProtests via @BBCWorld https://t.co/WgvMNMhbnj\n"
          ]
        }
      ],
      "source": [
        "# Try the personalized search function\n",
        "print(\"Insert your query (e.g., 'Disha Ravi'):\\n\")\n",
        "query = input()\n",
        "docs, scores = search_personalized_with_context(query, index, idf, tf, processed_data)\n",
        "top = 10\n",
        "\n",
        "print(\"\\n======================\\nTop {} results out of {} ranked documents for the searched query:\".format(top, len(docs)))\n",
        "for rank, (score, doc_id) in enumerate(scores[:top], start=1):\n",
        "    tweet_info = next((tweet for tweet in processed_data if tweet['DocID'] == doc_id), None)\n",
        "\n",
        "    if tweet_info:\n",
        "        # Print the rank, score, and original content of the tweet\n",
        "        print(\"\\n----------------------\\n\")\n",
        "        print(\"Rank: {} | Score: {:.4f}\".format(rank, score))\n",
        "        print(\"doc_id = {} \\ndoc_content = {}\".format(doc_id, tweet_info['Original Tweet']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW5ZEtdPYbIS"
      },
      "source": [
        "### 3.1.3. BM25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "8OSxYUZAYcqZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define BM25 parameters\n",
        "k1 = 1.2  # Controls term frequency scaling\n",
        "b = 0.75  # Controls document length normalization\n",
        "\n",
        "def rank_documents_bm25(query_terms, docs, index, idf, tf, avg_dl, doc_lengths):\n",
        "    \"\"\"\n",
        "    Rank documents based on BM25 scoring.\n",
        "\n",
        "    Parameters:\n",
        "    - query_terms: list of terms in the query\n",
        "    - docs: list of document IDs to rank\n",
        "    - index: inverted index data structure\n",
        "    - idf: dictionary of idf values for each term\n",
        "    - tf: dictionary of term frequencies for each term in documents\n",
        "    - avg_dl: average document length in the collection\n",
        "    - doc_lengths: dictionary mapping each document ID to its length\n",
        "\n",
        "    Returns:\n",
        "    - bm25_scores: list of tuples (BM25 score, doc ID), sorted by score in descending order\n",
        "    \"\"\"\n",
        "    bm25_scores = []\n",
        "\n",
        "    # For every document, compute the BM25 components for every term and for every query term\n",
        "    for doc in docs:\n",
        "        score = 0\n",
        "        dl = doc_lengths[doc]  # Length of the document\n",
        "        K = k1 * ((1 - b) + b * (dl / avg_dl))  # Normalization factor for document length\n",
        "\n",
        "        for term in query_terms:\n",
        "            if term in index and doc in [d[0] for d in index[term]]:\n",
        "                term_idf = idf[term]\n",
        "\n",
        "                # Find term frequency for the current document in `tf`\n",
        "                doc_index = [d[0] for d in index[term]].index(doc)\n",
        "                term_tf = tf[term][doc_index]  # Extract term frequency for doc in the list\n",
        "\n",
        "                # Calculate BM25 component for this term in the current document\n",
        "                score += term_idf * ((term_tf * (k1 + 1)) / (term_tf + K))\n",
        "\n",
        "        bm25_scores.append((score, doc))\n",
        "\n",
        "    # Sort scores in descending order\n",
        "    bm25_scores.sort(reverse=True, key=lambda x: x[0])\n",
        "    return bm25_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "z-tCOpgCY5Pg"
      },
      "outputs": [],
      "source": [
        "def search_bm25(query, index, idf, tf, avg_dl, doc_lengths, processed_data):\n",
        "    \"\"\"\n",
        "    Search for documents that contain all query terms and rank them using BM25.\n",
        "\n",
        "    Parameters:\n",
        "    - query: the search query string\n",
        "    - index: inverted index data structure\n",
        "    - idf: inverse document frequencies\n",
        "    - tf: term frequencies\n",
        "    - avg_dl: average document length in the collection\n",
        "    - doc_lengths: dictionary mapping each document ID to its length\n",
        "    - processed_data: list of tweet data\n",
        "\n",
        "    Returns:\n",
        "    - Ranked documents and their scores.\n",
        "    \"\"\"\n",
        "    # Tokenize and preprocess the query to get terms\n",
        "    query_terms = build_terms(query)\n",
        "    docs = None  # Start with None to allow initialization by the first term\n",
        "\n",
        "    # Find documents containing all query terms\n",
        "    for term in query_terms:\n",
        "        if term in index:\n",
        "            term_docs = set(posting[0] for posting in index[term])\n",
        "            docs = term_docs if docs is None else docs.intersection(term_docs)\n",
        "        else:\n",
        "            # If any term is not in the index, return an empty list (no matching docs)\n",
        "            return []\n",
        "\n",
        "    # If matching documents were found, rank them with BM25\n",
        "    if docs:\n",
        "        docs = list(docs)\n",
        "        ranked_docs = rank_documents_bm25(query_terms, docs, index, idf, tf, avg_dl, doc_lengths)\n",
        "        return ranked_docs\n",
        "    else:\n",
        "        return []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6jp0CfRY6kW",
        "outputId": "604e90f9-c739-4897-fff7-274eb1c0082c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert your query (e.g., 'Disha Ravi'):\n",
            "\n",
            "Increasing prices\n",
            "\n",
            "======================\n",
            "Top 10 results out of 109 ranked documents for the searched query:\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 1 | Score: 7.4081\n",
            "doc_id = doc_10847 \n",
            "doc_content = Khalisathan is responsible to increase price of diesel and petrol 😀 #farmersProtest #MSPLawForAllCrops\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 2 | Score: 6.1407\n",
            "doc_id = doc_33490 \n",
            "doc_content = Earlier,when the prices on petrol were increased, the concerns of Bollywood actors used to increase, but now petrol prices are continuously increasing.#IndiaBeingSilenced #FarmersProtest #FarmersProstests #FarmersStandingFirm #DishaRavi #PetrolPriceHike #CowardBJP #mondaythoughts\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 3 | Score: 5.3448\n",
            "doc_id = doc_27781 \n",
            "doc_content = What if I told you that the constant increase in the petrol prices is to move the attention from farmer's protest?\n",
            "\n",
            "#BJPdestroysDemocracy \n",
            "#FarmersProtest \n",
            "#FuelLoot \n",
            "#PetrolDieselPriceHike\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 4 | Score: 4.5215\n",
            "doc_id = doc_38875 \n",
            "doc_content = #fuel prices revised again . In 11 months #petrol have increased by 19.14 Rs.#Diesel by 16.77 Rs in #delhi . #14FebPulwamaBravehearts #Aandolanjeevi #FarmersProtest #Indianeconomy #JaiShriRam #RahulGandhi #PMModi https://t.co/sSCpHzVxzy\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 5 | Score: 4.4302\n",
            "doc_id = doc_30473 \n",
            "doc_content = Smriti Irani, aren’t you ashamed today of your  Government  for increasing petroleum and Gas  prices??\n",
            "#FarmersProtest \n",
            "#RepealOnlyWayAhead  \n",
            "#IndiaBeingSilenced \n",
            "#RememberSirChhotuRamInModiEra https://t.co/K7dQNIHEJ2\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 6 | Score: 4.4302\n",
            "doc_id = doc_899 \n",
            "doc_content = @ANI Govt should increased diesel price Rs 10,000 liter specially for misusing tractors 🚜 #PetrolPriceHike #FuelLootByBJP #FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 7 | Score: 4.4302\n",
            "doc_id = doc_28356 \n",
            "doc_content = Why does the price of everything else increase and sugarcane hasn't.  This is another way of exploiting Farmers!\n",
            "#FarmersProtest https://t.co/t4UnHTPZvf\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 8 | Score: 4.4302\n",
            "doc_id = doc_32144 \n",
            "doc_content = After increasing the price of petrol, now Modi ji will give cycle to Everyone for free, now you will be Happy.😀👇#IamAgainstModiGovt\n",
            "#ModiFuelScam #FarmersProtest https://t.co/WZepuESY0u\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 9 | Score: 4.4302\n",
            "doc_id = doc_30032 \n",
            "doc_content = @narendramodi Go and talk to our farmers. Stop looting us by increasing oil and gas price. #PetrolPriceHike #FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 10 | Score: 3.7947\n",
            "doc_id = doc_7119 \n",
            "doc_content = Why the outcry of petrol price increases,   If There is a higher price in Mumbai, so go to Mizoram and fill it up like a farmer can sell his crop anywhere💁‍♂\n",
            "#PetrolPriceHike\n",
            "#FarmersProtest https://t.co/eXJPmlw29m\n"
          ]
        }
      ],
      "source": [
        "# Calculate document lengths and average document length\n",
        "doc_lengths = {tweet['DocID']: len(tweet['Tokenized Tweet']) for tweet in processed_data}\n",
        "avg_dl = sum(doc_lengths.values()) / len(doc_lengths)\n",
        "\n",
        "# Try the BM25 search function\n",
        "print(\"Insert your query (e.g., 'Disha Ravi'):\\n\")\n",
        "query = input()\n",
        "ranked_docs = search_bm25(query, index, idf, tf, avg_dl, doc_lengths, processed_data)\n",
        "top = 10\n",
        "\n",
        "print(\"\\n======================\\nTop {} results out of {} ranked documents for the searched query:\".format(top, len(ranked_docs)))\n",
        "for rank, (score, doc_id) in enumerate(ranked_docs[:top], start=1):\n",
        "    tweet_info = next((tweet for tweet in processed_data if tweet['DocID'] == doc_id), None)\n",
        "\n",
        "    if tweet_info:\n",
        "        # Print the rank, score, and original content of the tweet\n",
        "        print(\"\\n----------------------\\n\")\n",
        "        print(\"Rank: {} | Score: {:.4f}\".format(rank, score))\n",
        "        print(\"doc_id = {} \\ndoc_content = {}\".format(doc_id, tweet_info['Original Tweet']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH4idut-YeyF"
      },
      "source": [
        "## 3.2. Top-20 using word2vec + cosine similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TBtABxYlh3C"
      },
      "source": [
        "###3.2.1. Word2Vec necessary functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqMVLrRfei5m"
      },
      "source": [
        "Train a Word2Vec model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "u8ETyMLZeci6"
      },
      "outputs": [],
      "source": [
        "# Prepare tokenized tweet data for training\n",
        "tokenized_tweets = [tweet['Tokenized Tweet'] for tweet in processed_data]\n",
        "\n",
        "# Train the Word2Vec model on the tokenized tweets\n",
        "word2vec_model = Word2Vec(sentences=tokenized_tweets, vector_size=100, window=5, min_count=2, workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owWRzAiWlp8Z"
      },
      "source": [
        "Compute the word2vec representation of our tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "cvEYjt0IewC7"
      },
      "outputs": [],
      "source": [
        "def compute_tweet_vector(tweet_tokens, model):\n",
        "    \"\"\"\n",
        "    Generate a tweet vector by averaging word vectors.\n",
        "\n",
        "    Parameters:\n",
        "    - tweet_tokens: list of words (tokens) in the tweet\n",
        "    - model: Word2Vec model\n",
        "\n",
        "    Returns:\n",
        "    - tweet_vector: Average vector of the words in the tweet\n",
        "    \"\"\"\n",
        "    vectors = []\n",
        "    for word in tweet_tokens:\n",
        "        if word in model.wv.key_to_index:  # Check if the word is in the model's vocabulary\n",
        "            vectors.append(model.wv[word])\n",
        "    if vectors:\n",
        "        tweet_vector = np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        tweet_vector = np.zeros(model.vector_size)  # Return a zero vector if no words are in the model\n",
        "    return tweet_vector\n",
        "\n",
        "# Generate tweet vectors and store them in a dictionary for quick access\n",
        "tweet_vectors = {tweet['DocID']: compute_tweet_vector(tweet['Tokenized Tweet'], word2vec_model) for tweet in processed_data}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5Mhx0bClvZa"
      },
      "source": [
        "rank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "kA_T5eLmhX2f"
      },
      "outputs": [],
      "source": [
        "def rank_documents_word2vec(query_vector, tweet_vectors):\n",
        "    \"\"\"\n",
        "    Rank documents based on cosine similarity with a given query vector.\n",
        "\n",
        "    Parameters:\n",
        "    - query_vector: numpy array representing the query\n",
        "    - tweet_vectors: dictionary with tweet DocIDs as keys and tweet vectors as values\n",
        "\n",
        "    Returns:\n",
        "    - ranked_docs: list of tuples (cosine similarity, DocID) sorted by similarity in descending order\n",
        "    \"\"\"\n",
        "    similarities = []\n",
        "    for doc_id, tweet_vector in tweet_vectors.items():\n",
        "        # Calculate cosine similarity using dot product and norms\n",
        "        dot_product = np.dot(query_vector, tweet_vector)\n",
        "        norm_query = np.linalg.norm(query_vector)\n",
        "        norm_tweet = np.linalg.norm(tweet_vector)\n",
        "\n",
        "        # Avoid division by zero\n",
        "        if norm_query == 0 or norm_tweet == 0:\n",
        "            similarity = 0.0\n",
        "        else:\n",
        "            similarity = dot_product / (norm_query * norm_tweet)\n",
        "\n",
        "        similarities.append((similarity, doc_id))\n",
        "\n",
        "    # Sort by similarity score in descending order\n",
        "    ranked_docs = sorted(similarities, key=lambda x: x[0], reverse=True)\n",
        "    return ranked_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaDZtjrXlw-j"
      },
      "source": [
        "search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "s3vYKuvWhpl5"
      },
      "outputs": [],
      "source": [
        "def search_word2vec_manual(query, tweet_vectors, processed_data, model, index):\n",
        "    \"\"\"\n",
        "    Search tweets based on cosine similarity using manually calculated dot product within the ranking function.\n",
        "\n",
        "    Parameters:\n",
        "    - query: search query string\n",
        "    - tweet_vectors: dictionary of tweet vectors (computed in advance)\n",
        "    - processed_data: list of tweet data\n",
        "    - model: Word2Vec model\n",
        "    - top_n: number of top results to return\n",
        "\n",
        "    Returns:\n",
        "    - top_results: list of tuples (cosine similarity, DocID)\n",
        "    \"\"\"\n",
        "    # Tokenize and preprocess the query\n",
        "    query_tokens = build_terms(query)\n",
        "\n",
        "    #Filter documents that contain all query terms in the same way as tf-idf\n",
        "    docs = None\n",
        "    for term in query_tokens:\n",
        "        try:\n",
        "            term_docs = set(posting[0] for posting in index[term])\n",
        "\n",
        "            if docs is None:\n",
        "                docs = term_docs\n",
        "            else:\n",
        "                docs = docs.intersection(term_docs) # (AND operation)\n",
        "        except KeyError:\n",
        "            return []\n",
        "\n",
        "    # Convert docs to a list if it's not empty\n",
        "    docs = list(docs)\n",
        "\n",
        "    #filter tweet vectors\n",
        "    filtered_tweet_vectors = {doc_id: tweet_vectors[doc_id] for doc_id in docs if doc_id in tweet_vectors}\n",
        "    #print(\"Filtered tweet vectors:\", filtered_tweet_vectors)\n",
        "    #print(\"Filtered tweet vectors length:\", len(filtered_tweet_vectors))\n",
        "\n",
        "    # Compute the query vector by averaging the vectors of query tokens\n",
        "    query_vector = compute_tweet_vector(query_tokens, model)\n",
        "\n",
        "    # Rank documents by similarity\n",
        "    #print(\"Tweet vectors:\", tweet_vectors)\n",
        "    #print(\"Tweet vectors length:\", len(tweet_vectors))\n",
        "    ranked_docs = rank_documents_word2vec(query_vector, filtered_tweet_vectors)\n",
        "\n",
        "    return ranked_docs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNlM4bSdlzLp"
      },
      "source": [
        "prompt to repeat for each query"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def search_word2vec(query, tweet_vectors, processed_data, word2vec_model):\n",
        "    # Assume the Word2Vec model and tweet vectors have already been generated\n",
        "    # word2vec_model = trained Word2Vec model\n",
        "    # tweet_vectors = dictionary of tweet DocIDs to their computed Word2Vec vectors\n",
        "\n",
        "    # Prompt the user for a query and perform the search using Word2Vec-based cosine similarity\n",
        "\n",
        "    # Use the Word2Vec-based search function to rank documents\n",
        "    ranked_docs = search_word2vec_manual(query, tweet_vectors, processed_data, word2vec_model, index)\n",
        "\n",
        "    # Display the top results\n",
        "    top = 20\n",
        "    print(\"\\n======================\\nTop {} results out of {} ranked documents for query: {}\".format(top, len(ranked_docs), query))\n",
        "    for rank, (score, doc_id) in enumerate(ranked_docs[:top], start=1):\n",
        "        tweet_info = next((tweet for tweet in processed_data if tweet['DocID'] == doc_id), None)\n",
        "\n",
        "        if tweet_info:\n",
        "            # Print the rank, score, and original content of the tweet\n",
        "            print(\"\\n----------------------\\n\")\n",
        "            print(\"Rank: {} | Score: {:.4f}\".format(rank, score))\n",
        "            print(\"doc_id = {} \\ndoc_content = {}\".format(doc_id, tweet_info['Original Tweet']))"
      ],
      "metadata": {
        "id": "7L6lC9pDlF6K"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGvgA5lelf6q"
      },
      "source": [
        "###3.2.2 Test for our 5 queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rz_ZmY9l7ta"
      },
      "source": [
        "Query 1: India government farmers protest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-j2E7zfl7Kx",
        "outputId": "1cfd4c5f-d657-498c-8f9d-eefc2fff0d8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================\n",
            "Top 20 results out of 55 ranked documents for query: India government farmers protest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 1 | Score: 0.9506\n",
            "doc_id = doc_39097 \n",
            "doc_content = To hear more about what led to widespread farmer protests in India &amp; what the government’s heavy-handed tactics for quashing dissent say about India’s future under Modi, listen to Worldly below @voxdotcom @jarielarvin\n",
            "\n",
            "#FarmersProtest #शहीद_जवान_शहीद_किसान https://t.co/GxYjDjChtp\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 2 | Score: 0.9424\n",
            "doc_id = doc_25562 \n",
            "doc_content = “Farmers across India have peacefully organized and protested for months. Yet they have faced violence, persecution, and retaliation by the government.”  #FarmersProtest https://t.co/jOGalK7Y2P\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 3 | Score: 0.9417\n",
            "doc_id = doc_8933 \n",
            "doc_content = 87 US farmers’ unions have extended solidarity to the ongoing protests by farmers in India and called the protests “one of the world’s most vibrant protests in history.” But this arrogant government will still remain adamant to implement #FarmLaws, won’t it? #FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 4 | Score: 0.9388\n",
            "doc_id = doc_45211 \n",
            "doc_content = @YourAnonCentral Please also highlight about the ongoing farmers protest in India... Farmers are protesting against the black farm laws. Government is continuously trying to suppress them by means which are challenging democracy #FarmersProtest  #BJPGovtDictatingTwitter\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 5 | Score: 0.9359\n",
            "doc_id = doc_17753 \n",
            "doc_content = #ReleaseDetainedFarmers\n",
            "\n",
            "The government have made #FarmLaws against all farmers.\n",
            "Now detaining farmers, if part of a 85 day long peaceful protest.\n",
            "\n",
            "All citizens of India should come together to support #FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 6 | Score: 0.9256\n",
            "doc_id = doc_30044 \n",
            "doc_content = Farmers are an integral part of any society. Peaceful protest is essential to preserving democracy &amp; the rule of law. \n",
            "\n",
            "This week, @jjhorgan wrote to @JustinTrudeau asking him to encourage the Indian Government to find a peaceful resolution to the #FarmersProtest in India. https://t.co/YD1ilO4Q0a\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 7 | Score: 0.9195\n",
            "doc_id = doc_30206 \n",
            "doc_content = Government is part of country whether it is Bjp in power or Congress or any third party. No Govt is neither above law nor  people.Why Government is feeling so offensive when people of India are supporting protesting farmers?\n",
            "#ReleaseDishaRavi\n",
            "#BJPdestroysDemocracy\n",
            "#FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 8 | Score: 0.9158\n",
            "doc_id = doc_27692 \n",
            "doc_content = Here's Solidarity Statement by concerned farmers, activists or Honored citizens of the world, For ongoing Indian farmer's Protest against Tyranny policies of Modi, Fascist Government of India \n",
            "Via @nytimes  #FarmersProtest\n",
            "#ReleaseDishaRavi https://t.co/O7qE38FtrU\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 9 | Score: 0.9092\n",
            "doc_id = doc_23037 \n",
            "doc_content = Why are farmers protesting in India, how is the Indian government responding, and what is the impact of the #FarmersProtest around the world? Listen via @thecarolinadesi's latest podcast episode --&gt; https://t.co/bkjuCleFMX. Take action --&gt; https://t.co/wQt69t7gOe https://t.co/kGe8IjfRWU\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 10 | Score: 0.9077\n",
            "doc_id = doc_7237 \n",
            "doc_content = @CNN\n",
            "@GLOBALNEWS \n",
            "@nytimes \n",
            "@CBCNews \n",
            "@BBCNews \n",
            "250 Indian farmers died in protests\n",
            "Deliberate attempt by Government to ignore farmers rights, &amp; devastating impact of these laws  on livelihoods of millions in India. \n",
            "#ModiIgnoringFarmersDeaths \n",
            "#RepealFarmLaws \n",
            "#FarmersProtest https://t.co/PGEw9p9W7R\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 11 | Score: 0.9026\n",
            "doc_id = doc_45744 \n",
            "doc_content = A great revolution is never the fault of the people, but of the government.\n",
            "\n",
            "Farmers in India are protesting against the injustice by government\n",
            "\n",
            "Support FARMERS✊🏽\n",
            "\n",
            "#FarmersProtest #MahapanchayatRevolution\n",
            "\n",
            " 12:28:10\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 12 | Score: 0.9026\n",
            "doc_id = doc_8970 \n",
            "doc_content = A great revolution is never the fault of the people, but of the government.\n",
            "\n",
            "Farmers in India are protesting against the injustice by government\n",
            "\n",
            "Support FARMERS✊🏽\n",
            "\n",
            "#FarmersProtest #DPstopIntimidatingFarmers\n",
            "\n",
            " 16:28:11\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 13 | Score: 0.9026\n",
            "doc_id = doc_32270 \n",
            "doc_content = A great revolution is never the fault of the people, but of the government.\n",
            "\n",
            "Farmers in India are protesting against the injustice by government\n",
            "\n",
            "Support FARMERS✊🏽\n",
            "\n",
            "#FarmersProtest #IndiaBeingSilenced\n",
            "\n",
            " 15:30:09\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 14 | Score: 0.9026\n",
            "doc_id = doc_31888 \n",
            "doc_content = A great revolution is never the fault of the people, but of the government.\n",
            "\n",
            "Farmers in India are protesting against the injustice by government\n",
            "\n",
            "Support FARMERS✊🏽\n",
            "\n",
            "#FarmersProtest #IndiaBeingSilenced\n",
            "\n",
            " 17:30:10\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 15 | Score: 0.9026\n",
            "doc_id = doc_32695 \n",
            "doc_content = A great revolution is never the fault of the people, but of the government.\n",
            "\n",
            "Farmers in India are protesting against the injustice by government\n",
            "\n",
            "Support FARMERS✊🏽\n",
            "\n",
            "#FarmersProtest #IndiaBeingSilenced\n",
            "\n",
            " 13:10:11\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 16 | Score: 0.9026\n",
            "doc_id = doc_8438 \n",
            "doc_content = A great revolution is never the fault of the people, but of the government.\n",
            "\n",
            "Farmers in India are protesting against the injustice by government\n",
            "\n",
            "Support FARMERS✊🏽\n",
            "\n",
            "#FarmersProtest\n",
            "\n",
            " 20:40:58\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 17 | Score: 0.9024\n",
            "doc_id = doc_10400 \n",
            "doc_content = A great revolution is never the fault of the people, but of the government.\n",
            "\n",
            "Farmers in India are protesting against the injustice by government\n",
            "\n",
            "Support FARMERS✊🏽\n",
            "\n",
            "#FarmersProtest #DPstopIntimidatingFarmers\n",
            "\n",
            " 05:14:11\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 18 | Score: 0.9022\n",
            "doc_id = doc_15326 \n",
            "doc_content = A great revolution is never the fault of the people, but of the government.\n",
            "\n",
            "Farmers in India are protesting against the injustice by government\n",
            "\n",
            "Support FARMERS✊🏽\n",
            "\n",
            "#FarmersProtest #ReleaseDetainedFarmers\n",
            "\n",
            " 21:28:11\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 19 | Score: 0.9018\n",
            "doc_id = doc_15195 \n",
            "doc_content = @BorisJohnson @DominicRaab The Indian government have stopped water supplies reaching the farmers protesting in Delhi. Surely now is the time to challenge them on their Human Rights breaches, or are trade deals with India more important to you both? #FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 20 | Score: 0.8922\n",
            "doc_id = doc_46118 \n",
            "doc_content = India: Government must stop crushing farmers’ protests and demonizing dissenters | Amnesty International #farmersprotest #istandwithfarmers https://t.co/E3V1RSRaeV\n"
          ]
        }
      ],
      "source": [
        "search_word2vec('India government farmers protest', tweet_vectors, processed_data, word2vec_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIRHYYYfmv4K"
      },
      "source": [
        "Query 2: Increasing prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz6Pw_xvm5YJ",
        "outputId": "eae26d5b-6dd8-4639-864b-7dec5ccd690c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================\n",
            "Top 20 results out of 109 ranked documents for query: Increasing prices\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 1 | Score: 0.9834\n",
            "doc_id = doc_10847 \n",
            "doc_content = Khalisathan is responsible to increase price of diesel and petrol 😀 #farmersProtest #MSPLawForAllCrops\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 2 | Score: 0.9578\n",
            "doc_id = doc_33490 \n",
            "doc_content = Earlier,when the prices on petrol were increased, the concerns of Bollywood actors used to increase, but now petrol prices are continuously increasing.#IndiaBeingSilenced #FarmersProtest #FarmersProstests #FarmersStandingFirm #DishaRavi #PetrolPriceHike #CowardBJP #mondaythoughts\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 3 | Score: 0.9395\n",
            "doc_id = doc_7119 \n",
            "doc_content = Why the outcry of petrol price increases,   If There is a higher price in Mumbai, so go to Mizoram and fill it up like a farmer can sell his crop anywhere💁‍♂\n",
            "#PetrolPriceHike\n",
            "#FarmersProtest https://t.co/eXJPmlw29m\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 4 | Score: 0.9291\n",
            "doc_id = doc_38875 \n",
            "doc_content = #fuel prices revised again . In 11 months #petrol have increased by 19.14 Rs.#Diesel by 16.77 Rs in #delhi . #14FebPulwamaBravehearts #Aandolanjeevi #FarmersProtest #Indianeconomy #JaiShriRam #RahulGandhi #PMModi https://t.co/sSCpHzVxzy\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 5 | Score: 0.8903\n",
            "doc_id = doc_27781 \n",
            "doc_content = What if I told you that the constant increase in the petrol prices is to move the attention from farmer's protest?\n",
            "\n",
            "#BJPdestroysDemocracy \n",
            "#FarmersProtest \n",
            "#FuelLoot \n",
            "#PetrolDieselPriceHike\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 6 | Score: 0.8900\n",
            "doc_id = doc_17267 \n",
            "doc_content = Why there is such hue and cry of increased fuel prices?\n",
            "If MP has the costliest petrol, you can always go to Assam to get cheaper petrol.\n",
            "Just like #Farmers can sell their produce wherever they get better price.\n",
            "\n",
            "#bhaktlogic \n",
            "#FarmersProtest \n",
            "#TakeBackFarmLaws https://t.co/vh6YLIeaBd\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 7 | Score: 0.8895\n",
            "doc_id = doc_30473 \n",
            "doc_content = Smriti Irani, aren’t you ashamed today of your  Government  for increasing petroleum and Gas  prices??\n",
            "#FarmersProtest \n",
            "#RepealOnlyWayAhead  \n",
            "#IndiaBeingSilenced \n",
            "#RememberSirChhotuRamInModiEra https://t.co/K7dQNIHEJ2\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 8 | Score: 0.8891\n",
            "doc_id = doc_14405 \n",
            "doc_content = Mosh: Farmers are protesting. World is watching it. We have to divert it some how. What to do? 🤔\n",
            "\n",
            "Increase petrol price. They will get diverted towards petrol price and forget farmers.\n",
            "\n",
            "&gt;&gt;Petrol price: 100\n",
            "\n",
            "#PetrolPrice #FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 9 | Score: 0.8828\n",
            "doc_id = doc_899 \n",
            "doc_content = @ANI Govt should increased diesel price Rs 10,000 liter specially for misusing tractors 🚜 #PetrolPriceHike #FuelLootByBJP #FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 10 | Score: 0.8825\n",
            "doc_id = doc_39498 \n",
            "doc_content = #GoBackModi #FarmersProtest #PetrolPrice #IStandWithFarmers\n",
            "The petrol price today in Ganganagar (Rajasthan) is Rs. 98.95 per Litre. The last change in Ganganagar's petrol price was on Feb 12, 2021 and it was increased by +0.54 rupees.\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 11 | Score: 0.8746\n",
            "doc_id = doc_3905 \n",
            "doc_content = @RahulGandhi If petrol diesel price go up, all train fair, food cost will get increase, then state govt will face struggle by GST, Food Grain FCI privatise Etc, So topple Will be easier 🚣🏊\n",
            "\n",
            "#FarmersProtest \n",
            "\n",
            "#FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 12 | Score: 0.8729\n",
            "doc_id = doc_14293 \n",
            "doc_content = @manswinni @kaurraman00 So Indians already reeling from soaring fuel price, falling GDP and ever increasing inflation are  going to have to eat Gobar (if they can afford it)\n",
            "\n",
            "#FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 13 | Score: 0.8689\n",
            "doc_id = doc_20156 \n",
            "doc_content = @ShashiTharoor I am surprised that nobody seems to be investigating the work of Adani Group in terms of their share price increase ambitions. Is this the underlying reason for price hikes?\n",
            "\n",
            "#RailRokoForFarmers\n",
            "#FarmersProtest https://t.co/V0YG9MKNpC\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 14 | Score: 0.8657\n",
            "doc_id = doc_19268 \n",
            "doc_content = Petrol price crosses Rs 100 per liter mark in Madhya Pradesh after fuel rates were increased for the tenth day in a row  #FarmersProtest  Acche din a gyeeee 🤣🤣🤣🤣🤣🤣🤣🤣 https://t.co/1tOZGpU0xg\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 15 | Score: 0.8654\n",
            "doc_id = doc_20089 \n",
            "doc_content = #FarmersProtest | Crops' prices are not increased, but fuel prices have gone up. If Centre ruins the situation, we'll take our tractors to #WestBengal as well. Farmers not getting MSP there also: @RakeshTikaitBKU in Kharak Punia, #Haryana \n",
            "\n",
            "ANI https://t.co/xHqBRJH4nQ\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 16 | Score: 0.8626\n",
            "doc_id = doc_5447 \n",
            "doc_content = The government is saying at the high price of petrol and diesel that it is not in our hands but in the hands of private companies. Tomorrow the government will say the same on the increased rates of dal rice, flour, sugar etc.#Farmers #FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 17 | Score: 0.8571\n",
            "doc_id = doc_18776 \n",
            "doc_content = Crops' prices are not increased, but fuel prices have gone up. If Centre ruins the situation, we'll take our tractors to West Bengal: Rakesh Tikait\n",
            "\n",
            "#FarmersProtest \n",
            "\n",
            "https://t.co/1C2a7DCHbj\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 18 | Score: 0.8457\n",
            "doc_id = doc_5882 \n",
            "doc_content = #Verified\n",
            "\n",
            "👉Rakesh Tikait in RAJASTHAN's\n",
            "#FarmersProtest Panchayat\n",
            "\n",
            "👉'Corporates manipulate prices once they have monopoly'\n",
            "\n",
            "👉'Look at flights. If there are 2 tickets &amp; 5 buyers, they increase ticket's cost'\n",
            "\n",
            "👉'Companies will do same manipulation of your food using #FarmLaws' https://t.co/9thiPNOHF4\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 19 | Score: 0.8348\n",
            "doc_id = doc_28356 \n",
            "doc_content = Why does the price of everything else increase and sugarcane hasn't.  This is another way of exploiting Farmers!\n",
            "#FarmersProtest https://t.co/t4UnHTPZvf\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 20 | Score: 0.8334\n",
            "doc_id = doc_34041 \n",
            "doc_content = With the Petrol Diesel prices increasing for 5th consecutive day, AndhBhakts will claim its Modi Ji's fight against Global warming and Carbon emission !!🙈🤭\n",
            "#PetrolPrice \n",
            "#agriculture \n",
            "#KisanAndolan \n",
            "#Koo \n",
            "#Farmers \n",
            "#FarmersProtest \n",
            "#ModiHaiToMumkinHai\n"
          ]
        }
      ],
      "source": [
        "search_word2vec('Increasing prices', tweet_vectors, processed_data, word2vec_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_TCRSHXnEhJ"
      },
      "source": [
        "Query 3: Narendra Modi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6G6hzTwnG2N",
        "outputId": "e3c412ba-653f-4da2-be74-ebda89b2a774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================\n",
            "Top 20 results out of 69 ranked documents for query: Narendra Modi\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 1 | Score: 0.9029\n",
            "doc_id = doc_9065 \n",
            "doc_content = If prime minister narendra modi knows better whey’not he is teaching them?? #FarmersProtest https://t.co/uGwbsaFbA6\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 2 | Score: 0.8845\n",
            "doc_id = doc_13190 \n",
            "doc_content = Narendra Modi should answer why did Vijay Mallya, Nirav Modi , Mehul Chowksi and several private sector fraudster ran away with public money?\n",
            "B4 preaching privatisation 😡\n",
            "\n",
            "#modi #bjp #bjplies #bjpfails #FarmersProtest #AtmaNirbharBharat \n",
            "\n",
            "https://t.co/HMS5N1gWZz\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 3 | Score: 0.8685\n",
            "doc_id = doc_26001 \n",
            "doc_content = I dare you, amit shah and narendra modi to contest from punjab @smritiirani @SmritiIraniOffc \n",
            "#FarmersMakeIndia \n",
            "#FarmersProtest https://t.co/CpTZPjTpst\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 4 | Score: 0.8637\n",
            "doc_id = doc_17153 \n",
            "doc_content = I dislike Shri Narendra Modi, because his political ideology is \"divide and rule\".\n",
            "\n",
            "@sushant_says \n",
            "@BJP4India \n",
            "#FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 5 | Score: 0.8564\n",
            "doc_id = doc_28808 \n",
            "doc_content = Entrepreneurs hail Narendra Modi government's move to free up mapping\n",
            "https://t.co/oU3ux6U6K7\n",
            "\n",
            "#WestBengal #TamilNadu #assam #ModiJiPrideOfIndia\n",
            "#IStandWithKapilMishra \n",
            "#BJP #TeamIndia #IndiavsEngland\n",
            "#IndiaBeingSilenced #ArrestDilipMandal\n",
            "#agriculture #FarmersProtest #Farmers https://t.co/sS0CpvzOc0\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 6 | Score: 0.8552\n",
            "doc_id = doc_30071 \n",
            "doc_content = ‘Prime Minister Narendra Modi is no stranger to sparking public anger with his determination to push through reforms, but this may be his most vital stand-off yet.’\n",
            "@straits_times \n",
            "\n",
            "#FarmersProtest #RememberSirChhotuRamInModiEra \n",
            "https://t.co/kbAAI4b1r7\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 7 | Score: 0.8537\n",
            "doc_id = doc_33052 \n",
            "doc_content = How Long Will Joe Biden Pretend Narendra Modi's India Is a Democratic Ally?\n",
            "\n",
            "#FarmersProtest #IndiaBeingSilenced https://t.co/hO1QNgpy6g\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 8 | Score: 0.8493\n",
            "doc_id = doc_44209 \n",
            "doc_content = @narendramodi @JustinTrudeau Narendra Modi did not make vaccine it's mind of indian people that they are able to make vaccine. So shameful to see that justin trudeau is doing everything to save his country people And  Modi wants to kill his own people. Feeling shamful to call you our PM #FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 9 | Score: 0.8475\n",
            "doc_id = doc_29991 \n",
            "doc_content = ‘It took just one tweet from Rihanna to anger the Indian government and supporters of Prime Minister Narendra Modi's party.’ @ChannelNewsAsia\n",
            "\n",
            "#FarmersProtest #RememberSirChhotuRamInModiEra \n",
            "https://t.co/ullIBUaPCw\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 10 | Score: 0.8410\n",
            "doc_id = doc_24265 \n",
            "doc_content = \"How Long Will Joe Biden Pretend Narendra Modi's India Is a Democratic Ally going Autocracy?\n",
            "\n",
            "#HumDoHamareDo \n",
            "#AmbaniAdanijeevi\n",
            "#FarmersProtest \n",
            "#supportfarmers \n",
            "#SupportFarmersProtest \n",
            "#StandWithFarmers\n",
            "\n",
            " https://t.co/4FSQe7tZzs\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 11 | Score: 0.8403\n",
            "doc_id = doc_40724 \n",
            "doc_content = Once Dr. Manmohan Singh said, \"it will be a disaster If Narendra Modi becomes PM of India\".  \n",
            "\n",
            "And I didn't believe him that time.\n",
            "#FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 12 | Score: 0.8316\n",
            "doc_id = doc_29821 \n",
            "doc_content = Prime Minister Narendra Modi installed a statue of Jat leader Sir Chhotu Ram in Haryana but at the same time he is busy destroying his legacy of farmers rights #FarmersProtest #RememberSirChhotuRamInModiEra\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 13 | Score: 0.8275\n",
            "doc_id = doc_34208 \n",
            "doc_content = @BBCIndia’s correspondent @soutikBBC says that Prime Minister Narendra Modi has “misread the mood of India’s angry farmers” with his reforms, which have sparked accusations of “crony capitalism”.\n",
            "@TheWeek \n",
            "\n",
            "#FarmersProtest #IndiaBeingSilenced \n",
            "https://t.co/hm2Q9nMmJ4\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 14 | Score: 0.8259\n",
            "doc_id = doc_6438 \n",
            "doc_content = Because he follows oppress and dictate policy. Narendra modi killing democracy in India and bhakts are enjoying.  \n",
            "#ModiIgnoringFarmersDeaths #FarmersProtest https://t.co/PVcysosPf8\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 15 | Score: 0.8250\n",
            "doc_id = doc_42179 \n",
            "doc_content = #Jaipur | Congress leader Rahul Gandhi (@RahulGandhi) alleged that Prime Minister Narendra Modi wants to \"hand over\" the entire agriculture business to his \"two friends\".\n",
            "\n",
            "#Rajasthan #FarmersProtest #RahulGandhiInRajasthan #FarmLaw @INCRajasthan \n",
            "\n",
            "https://t.co/6ZRy79fxfj\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 16 | Score: 0.8204\n",
            "doc_id = doc_40331 \n",
            "doc_content = Yes, I am sure this to be end result of #FarmersProtest , Narendra Modi to own his mistakes, to resign, it so pure movement! #GoBackFascistModi\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 17 | Score: 0.8123\n",
            "doc_id = doc_42686 \n",
            "doc_content = Earlier on Thursday, Mr Gandhi had said that Prime Minister Narendra Modi is running the country on a “hum do, hamare do” (we two, our two) principle. | HW English #Cronies #FarmersProtest #Featured #NirmalaSitharaman #RahulGandhi https://t.co/4KC5dMhEPT\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 18 | Score: 0.8078\n",
            "doc_id = doc_32543 \n",
            "doc_content = The darkest decade for Indian democracy !!!\n",
            "Since taking power Narendra Modi has dismantled the nation’s secular traditions, but there are signs Indians have had enough !! \n",
            "#Farmers #FarmersProtest #KisanAndolan https://t.co/f79ZbFUK3I\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 19 | Score: 0.8043\n",
            "doc_id = doc_32829 \n",
            "doc_content = #FarmersProtest | Congress leader @PriyankaGandhi attacks Prime Minister Narendra Modi over the farmers’ protests against the #farmlaws passed by the Centre. https://t.co/i0onRjJAbQ\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 20 | Score: 0.8042\n",
            "doc_id = doc_6505 \n",
            "doc_content = #FarmersProtest | \"These laws are designed to destroy the agricultural system in India &amp; give the entire business to 2-3 Narendra Modi's friends\", says @RahulGandhi. \n",
            "\n",
            "Read: https://t.co/T2kI0yLmRx https://t.co/NUAxCX9s3X\n"
          ]
        }
      ],
      "source": [
        "search_word2vec('Narendra Modi', tweet_vectors, processed_data, word2vec_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDSHpnYFn03H"
      },
      "source": [
        "Query 4: Disha Ravi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAyhmJHsn0pu",
        "outputId": "4b8cfda6-edcc-4402-a161-bf23f59ee57d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================\n",
            "Top 20 results out of 628 ranked documents for query: Disha Ravi\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 1 | Score: 1.0000\n",
            "doc_id = doc_32205 \n",
            "doc_content = #IndiaBeingSilenced \n",
            "#farmersprotest \n",
            "Disha ravi https://t.co/OVmvJy3d8V\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 2 | Score: 1.0000\n",
            "doc_id = doc_11995 \n",
            "doc_content = #FarmersProtest. Disha Ravi. https://t.co/VbW9rYLUIa\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 3 | Score: 0.9996\n",
            "doc_id = doc_35462 \n",
            "doc_content = #FreeDishaRavi \n",
            "#FarmersProtest\n",
            "Freezer Disha Ravi nowwww https://t.co/PP9KwfiVrD\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 4 | Score: 0.9985\n",
            "doc_id = doc_10044 \n",
            "doc_content = Hats off to Disha Ravi..\n",
            "\n",
            "#FarmersProtest https://t.co/5QjLp5BVuQ\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 5 | Score: 0.9901\n",
            "doc_id = doc_35814 \n",
            "doc_content = Release Disha Ravi \n",
            "\n",
            "#शहीद_जवान_शहीद_किसान\n",
            "#FarmersProtest https://t.co/KhaEkCejac\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 6 | Score: 0.9901\n",
            "doc_id = doc_35520 \n",
            "doc_content = Release Disha Ravi .\n",
            "\n",
            "#शहीद_जवान_शहीद_किसान #DishaRavi #FarmersProtest https://t.co/43giAGdkdt\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 7 | Score: 0.9901\n",
            "doc_id = doc_30467 \n",
            "doc_content = #farmersprotest\n",
            "Release Disha Ravi https://t.co/QsVdv1V6dH\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 8 | Score: 0.9901\n",
            "doc_id = doc_28156 \n",
            "doc_content = #FarmersProtest                          Release Disha Ravi.. https://t.co/2Jd5dOJuDm\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 9 | Score: 0.9901\n",
            "doc_id = doc_35482 \n",
            "doc_content = #ReleaseDishaRavi \n",
            "#FarmersProtest\n",
            "Release Disha Ravi https://t.co/erHWsfvOjf\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 10 | Score: 0.9880\n",
            "doc_id = doc_32022 \n",
            "doc_content = Petition to release Disha Ravi. #farmersprotest #ReleaseDishaRavi #releasenodeep https://t.co/31LdactqX8\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 11 | Score: 0.9838\n",
            "doc_id = doc_6452 \n",
            "doc_content = Adv. Siddharth Agarwal is appearing on behalf of Disha Ravi.\n",
            "\n",
            "#DishaRavi\n",
            "#ToolKit \n",
            "#ToolkitCase \n",
            "#FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 12 | Score: 0.9760\n",
            "doc_id = doc_26980 \n",
            "doc_content = #FarmersProtest \n",
            "FREE DISHA RAVI https://t.co/LIPcOBb9DE\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 13 | Score: 0.9760\n",
            "doc_id = doc_35225 \n",
            "doc_content = Free Disha Ravi \n",
            "\n",
            "#FarmersProtest  #IndiaBeingSilenced\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 14 | Score: 0.9760\n",
            "doc_id = doc_35479 \n",
            "doc_content = #ReleaseDishaRavi \n",
            "#FarmersProtest\n",
            "Free Disha Ravi now https://t.co/6ICewg90o8\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 15 | Score: 0.9760\n",
            "doc_id = doc_26970 \n",
            "doc_content = #FarmersProtest \n",
            "FREE DISHA RAVI https://t.co/PnwSkMJSu2\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 16 | Score: 0.9760\n",
            "doc_id = doc_26979 \n",
            "doc_content = #FarmersProtest \n",
            "FREE DISHA RAVI https://t.co/QnOTDGBvud\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 17 | Score: 0.9760\n",
            "doc_id = doc_26971 \n",
            "doc_content = #FarmersProtest \n",
            "FREE DISHA RAVI https://t.co/DP2vGtaZLB\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 18 | Score: 0.9760\n",
            "doc_id = doc_26974 \n",
            "doc_content = #FarmersProtest \n",
            "FREE DISHA RAVI https://t.co/3Sdi1nsDhh\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 19 | Score: 0.9759\n",
            "doc_id = doc_3089 \n",
            "doc_content = DISHA RAVI FREED ON BAIL.. \n",
            "\n",
            "😇👍👍✌✌\n",
            "#FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 20 | Score: 0.9753\n",
            "doc_id = doc_29046 \n",
            "doc_content = Why you arrested disha ravi release\n",
            "#DishaRavi #FarmersProtest https://t.co/FJu7VkSUSj\n"
          ]
        }
      ],
      "source": [
        "search_word2vec('Disha Ravi', tweet_vectors, processed_data, word2vec_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHyGDmgsn_vv"
      },
      "source": [
        "Query 5: Anime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnkekx7OoCYX",
        "outputId": "22f8592c-36fc-492e-b18c-b71acfd1231f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================\n",
            "Top 20 results out of 25 ranked documents for query: Anime\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 1 | Score: 0.9213\n",
            "doc_id = doc_1565 \n",
            "doc_content = The guy wearing blue turban is my spirit animal.\n",
            "\n",
            "#FarmersProtest https://t.co/0iX9YaLNmW\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 2 | Score: 0.8546\n",
            "doc_id = doc_23921 \n",
            "doc_content = ‘He will win whose army is animated by the same spirit throughout all its ranks’ The art of war #SunTzu. It’s vital the leaders stand with all those falsely imprisoned and not throw anyone under the bus. #FreeDeepSidhu #FreeNodeepKaur #FreeDishaRavi #LakhaSidhana #FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 3 | Score: 0.8525\n",
            "doc_id = doc_38825 \n",
            "doc_content = Unacceptable!!!   The fact that @DelhiPolice assumed beating an elderly man was normal and acceptable is disgraceful.   You animals have zero compassion or regard  for human life.  #farmersprotest https://t.co/1WdbhH1xVa\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 4 | Score: 0.8396\n",
            "doc_id = doc_33877 \n",
            "doc_content = Modi stray dogs can bark I m sorry throwing stone on a rabid animal is not my theory I will just put u out of ur misery \n",
            "U can't affect an ounce of my mental peace now keep on commenting \n",
            "#FarmersProtest #IndiaBeingSilenced\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 5 | Score: 0.8171\n",
            "doc_id = doc_9184 \n",
            "doc_content = @HansrajMeena @rihanna 👌🏻👌🏻\n",
            "Hey. I boycotted Bollywood immediately after the 1st month I saw that these bullshit celebrities havent said a word in support of our #FarmersProtest ✊🏻\n",
            "Animals are way better than these ppl🤬\n",
            "#shameonbollywood\n",
            "#BoycottBollywood\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 6 | Score: 0.8124\n",
            "doc_id = doc_45935 \n",
            "doc_content = All animals are equal but some animals are more equal than others.\n",
            "#FarmersProtest https://t.co/4NtTKIj2sF\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 7 | Score: 0.8123\n",
            "doc_id = doc_22596 \n",
            "doc_content = \"while the Modi-Shah regime fears independent thinking in general, they particularly fear it when expressed by young people... animated by ideals of religious pluralism, caste and gender justice\"\n",
            "#DishaRavi \n",
            "#NodeepKaur \n",
            "#FarmersProtest \n",
            "\n",
            "https://t.co/JSoDRQcDsB\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 8 | Score: 0.7901\n",
            "doc_id = doc_18266 \n",
            "doc_content = In a very unique and sweet way, even the animals and their  guardians have come out to support the #farmersprotest in #Chandigarh https://t.co/3HWVaIsmhW\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 9 | Score: 0.7854\n",
            "doc_id = doc_24034 \n",
            "doc_content = @ANI Hey #Pappu, these are two separate ministries, at least educate yourself!\n",
            "\n",
            "1. Ministry of Agriculture &amp; Farmers Welfare \n",
            " \n",
            "2. Ministry of Fisheries, Animal husbandry &amp; Dairying\n",
            "\n",
            "#Congress still persisting with this idiot ignorant?\n",
            "\n",
            "Not a #FarmersProtest #RaGa #KisanAndolan\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 10 | Score: 0.7850\n",
            "doc_id = doc_13262 \n",
            "doc_content = FM urges industry to unleash animal spirits, make India fastest growing economy - The Hindu#farmers #farmersprotest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 11 | Score: 0.7845\n",
            "doc_id = doc_34980 \n",
            "doc_content = All Men Are Enemies. All Animals Are Comrades: George Orwell's #Toolkit For Rebellion\n",
            "\n",
            "Be A #Bookaanan, Read\n",
            "Animal Farm\n",
            "https://t.co/gwARnQCJn8\n",
            "#Nationalism #FarmersProtest #inquilab #inquilabzindabad #IndiaTogether #IndiaBeingSilenced #GretaThunberg #Khalistan #Dystopian #india https://t.co/yRXUw4jys0\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 12 | Score: 0.7800\n",
            "doc_id = doc_45983 \n",
            "doc_content = In countries like UK, Australia barbed wire n spike fencing barriers  is only permitted in industrial and rural areas, and must comply with strict council laws to protect animals and humans from injury.\n",
            "\n",
            "Our farmers in India are humans too\n",
            "#MahapanchayatRevolution\n",
            "#FarmersProtest https://t.co/pIbl1JLGr4\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 13 | Score: 0.7773\n",
            "doc_id = doc_33414 \n",
            "doc_content = All animals are equal some are more equal than others. #DishaRavi  #FarmersProtest https://t.co/uEgxyx3fCZ\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 14 | Score: 0.7600\n",
            "doc_id = doc_32190 \n",
            "doc_content = Did you see two other animals there, the donkey(modi) and the rhino(amit shah)? #FarmersProtest #IndiaBeingSilenced #FarmerProtests #BoycottBJP https://t.co/bvTjsGbX8I\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 15 | Score: 0.7600\n",
            "doc_id = doc_36532 \n",
            "doc_content = Did you see two other animals there, the donkey(modi) and the rhino(amit shah)? #FarmersProtest #FarmerProtests #BoycottBJP https://t.co/bvTjsGbX8I\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 16 | Score: 0.7476\n",
            "doc_id = doc_44926 \n",
            "doc_content = @meenaharris You do right thing so just keep it up we are with you and thankful to you . Who’s comments are abuses they are not really humans they are animals in human body so don’t waste your time to read their comments. #FreeNodeepKaur #FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 17 | Score: 0.7323\n",
            "doc_id = doc_15505 \n",
            "doc_content = This is just horrible in so many different ways. Even animals are treated better. Absolutely no humanity left\n",
            "#FarmersProtest \n",
            "#ReleaseDetainedFarmers https://t.co/PgdTwPqVAn\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 18 | Score: 0.7274\n",
            "doc_id = doc_9089 \n",
            "doc_content = Humans and animals both are not safe in this country anymore\n",
            "\n",
            "This is an era of inhumans\n",
            "\n",
            "#ModiGlobalDisaster \n",
            "#FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 19 | Score: 0.7155\n",
            "doc_id = doc_25231 \n",
            "doc_content = Farmer is a magician who produces money from the mud.They are merely considered as animals growing food for us.\n",
            "We should respect them &amp; consider their demands seriously.\n",
            "\n",
            "Make India Great Again!! 🇮🇳 \n",
            "#FarmersProtest\n",
            "#FarmersMakeIndia https://t.co/GfVfBaI23k\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 20 | Score: 0.7074\n",
            "doc_id = doc_12134 \n",
            "doc_content = India treats it’s war heroes worse than animals.\n",
            "#FarmersProtest \n",
            "#freeNodeeoKaur https://t.co/Qfobp2SdRy\n"
          ]
        }
      ],
      "source": [
        "search_word2vec('Anime', tweet_vectors, processed_data, word2vec_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQoL8cRTYmsg"
      },
      "source": [
        "## 3.3. Better representation than word2vec?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zVS2vuSkwqK"
      },
      "source": [
        "###3.3.1. Trying Doc2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "PbwK_LoRYrsX"
      },
      "outputs": [],
      "source": [
        "# Sample 20% of the data - otherwise we have a memory error\n",
        "sample_size = int(0.01 * len(processed_data))\n",
        "sampled_data = random.sample(processed_data, sample_size)\n",
        "\n",
        "# Create tagged data from the sample\n",
        "tagged_data = [TaggedDocument(words=tweet['Tokenized Tweet'], tags=[tweet['TweetID']]) for tweet in sampled_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "xTz-uo7_lXew",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "924ac69f-6c58-4d12-8087-2adc63afacba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.doc2vec:Highest int doctag (1364503376885473282) larger than count of documents (484). This means at least 1364503376885472798 excess, unused slots (54580135075418911920 bytes) will be allocated for vectors.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "MemoryError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-2684dd627dcc>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the Doc2Vec model on the tokenized tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdoc2vec_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdoc2vec_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagged_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdoc2vec_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagged_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoc2vec_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoc2vec_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, corpus_iterable, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \"\"\"\n\u001b[0;32m--> 882\u001b[0;31m         total_words, corpus_count = self.scan_vocab(\n\u001b[0m\u001b[1;32m    883\u001b[0m             \u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m             \u001b[0mprogress_per\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_per\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mscan_vocab\u001b[0;34m(self, corpus_iterable, corpus_file, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m   1052\u001b[0m             \u001b[0mcorpus_iterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTaggedLineDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m         \u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scan_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_per\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m         logger.info(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36m_scan_vocab\u001b[0;34m(self, corpus_iterable, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoctags_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m                 \u001b[0mdoctags_lookup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoctags_lookup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmax_rawint\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0mdoctags_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_rawint\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdoctags_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_to_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoctags_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMemoryError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train the Doc2Vec model on the tokenized tweets\n",
        "doc2vec_model = Doc2Vec(vector_size=10, window=3, min_count=2, workers=4, epochs=10)\n",
        "doc2vec_model.build_vocab(tagged_data)\n",
        "doc2vec_model.train(tagged_data, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doc2Vec needs too much memory. Although, had we access to a huge source of memory, we believe that it could improve Word2Vec performance."
      ],
      "metadata": {
        "id": "drIcdy5eFwxK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PsiIzAOmaUG"
      },
      "source": [
        "###3.3.2. Trying Sentence2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Too much expensive to be used for practical purposes. Training is too slow. (explained in the report)"
      ],
      "metadata": {
        "id": "VOg3UuQwOs1D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "V2WGMqB7mZH4",
        "outputId": "0d89d26d-f44f-4cb7-ddbf-767369e7ce61"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-9e3b74ef41ee>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# tweet vectors by encoding entire tweets (sentences)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtweet_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TweetID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msentence_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Original Tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocessed_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-9e3b74ef41ee>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# tweet vectors by encoding entire tweets (sentences)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtweet_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TweetID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msentence_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Original Tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocessed_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 \u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"hpu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m                     \u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mmodule_kwarg_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mmodule_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule_kwarg_keys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mtrans_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0moutput_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrans_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0moutput_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1143\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    693\u001b[0m                 )\n\u001b[1;32m    694\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    696\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    628\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Initialize SentenceTransformer model (using pre-trained model)\n",
        "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# tokenized tweet data for training\n",
        "tokenized_tweets = [tweet['Original Tweet'] for tweet in processed_data]\n",
        "\n",
        "# tweet vectors by encoding entire tweets (sentences)\n",
        "tweet_vectors = {tweet['TweetID']: sentence_model.encode(tweet['Original Tweet']) for tweet in processed_data}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.3.3. GloVe"
      ],
      "metadata": {
        "id": "8LtYdZeV68Cm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you don't have *glove.6B.300d.txt* downloaded, execute commented cells below"
      ],
      "metadata": {
        "id": "I0B67aZPNUny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IgUJZlt7ADw",
        "outputId": "0fd3dace-411b-45f2-dcc6-1a6def9440ed"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-14 15:13:42--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2024-11-14 15:13:42--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-11-14 15:13:42--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 43s  \n",
            "\n",
            "2024-11-14 15:16:25 (5.05 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HDQ4W257A5a",
        "outputId": "44233ece-680a-4053-8d73-f06a20741d4d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_model = gensim.models.KeyedVectors.load_word2vec_format('glove.6B.300d.txt', no_header=True)\n"
      ],
      "metadata": {
        "id": "J_ynFj2V7BLA"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_tweet_vector(tweet_tokens, glove_model):\n",
        "    \"\"\"\n",
        "    Generate a tweet vector by averaging the word vectors.\n",
        "\n",
        "    Parameters:\n",
        "    - tweet_tokens: list of words (tokens) in the tweet\n",
        "    - glove_model: pre-loaded GloVe word vectors\n",
        "\n",
        "    Returns:\n",
        "    - tweet_vector: Average vector of the words in the tweet\n",
        "    \"\"\"\n",
        "    vectors = []\n",
        "    for word in tweet_tokens:\n",
        "        if word in glove_model:  # Check if the word exists in GloVe model\n",
        "            vectors.append(glove_model[word])\n",
        "    if vectors:\n",
        "        tweet_vector = np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        tweet_vector = np.zeros(glove_model['the'].shape)  # Use zeros vector if no words are in the model\n",
        "    return tweet_vector"
      ],
      "metadata": {
        "id": "IutvSXfU7SKi"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare tweet vectors for ranking\n",
        "tweet_vectors = {tweet['DocID']:compute_tweet_vector(tweet['Tokenized Tweet'], glove_model) for tweet in processed_data}"
      ],
      "metadata": {
        "id": "MeaeirxRBndw"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rank_documents_glove(query_vector, tweet_vectors):\n",
        "    \"\"\"\n",
        "    Rank documents (tweets) based on cosine similarity with the query vector.\n",
        "\n",
        "    Parameters:\n",
        "    - query_vector: numpy array representing the query\n",
        "    - tweet_vectors: dictionary with tweet DocIDs as keys and tweet vectors as values\n",
        "\n",
        "    Returns:\n",
        "    - ranked_docs: list of tuples (cosine similarity, DocID) sorted by similarity in descending order\n",
        "    \"\"\"\n",
        "    similarities = []\n",
        "    for doc_id, tweet_vector in tweet_vectors.items():\n",
        "        dot_product = np.dot(query_vector, tweet_vector)\n",
        "        norm_query = np.linalg.norm(query_vector)\n",
        "        norm_tweet = np.linalg.norm(tweet_vector)\n",
        "\n",
        "        if norm_query == 0 or norm_tweet == 0:\n",
        "            similarity = 0.0\n",
        "        else:\n",
        "            similarity = dot_product / (norm_query * norm_tweet)\n",
        "\n",
        "        similarities.append((similarity, doc_id))\n",
        "\n",
        "    ranked_docs = sorted(similarities, key=lambda x: x[0], reverse=True)\n",
        "    return ranked_docs\n"
      ],
      "metadata": {
        "id": "2re5aRJw8bbJ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_glove(query, tweet_data, glove_model):\n",
        "    \"\"\"\n",
        "    Search for tweets based on GloVe embeddings by computing cosine similarity with the query.\n",
        "\n",
        "    Parameters:\n",
        "    - query: Search query string.\n",
        "    - tweet_data: List of tweet data, each containing a 'DocID' and 'Original Tweet'.\n",
        "    - glove_model: Pre-trained GloVe model.\n",
        "\n",
        "    Returns:\n",
        "    - ranked_docs: List of tuples (cosine similarity, DocID) sorted by similarity in descending order.\n",
        "    \"\"\"\n",
        "    # Preprocess the query and compute the query vector\n",
        "    query_tokens = build_terms(query)\n",
        "    query_vector = compute_tweet_vector(query_tokens, glove_model)\n",
        "\n",
        "    #Filter documents that contain all query terms in the same way as tf-idf\n",
        "    docs = None\n",
        "    for term in query_tokens:\n",
        "        try:\n",
        "            term_docs = set(posting[0] for posting in index[term])\n",
        "\n",
        "            if docs is None:\n",
        "                docs = term_docs\n",
        "            else:\n",
        "                docs = docs.intersection(term_docs) # (AND operation)\n",
        "        except KeyError:\n",
        "            return []\n",
        "\n",
        "    # Convert docs to a list if it's not empty\n",
        "    docs = list(docs)\n",
        "    filtered_tweet_vectors = {doc_id: tweet_vectors[doc_id] for doc_id in docs if doc_id in tweet_vectors}\n",
        "    # Rank tweets based on similarity\n",
        "    ranked_docs = rank_documents_glove(query_vector, filtered_tweet_vectors)\n",
        "    return ranked_docs"
      ],
      "metadata": {
        "id": "II29w2yE9f4L"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Insert your query (e.g., 'Disha Ravi'):\\n\")\n",
        "query = input()\n",
        "ranked_docs = search_glove(query, tweet_vectors, glove_model)\n",
        "top = 10\n",
        "\n",
        "# Display the top results\n",
        "top = 20\n",
        "print(\"\\n======================\\nTop {} results out of {} ranked documents for query: {}\".format(top, len(ranked_docs), query))\n",
        "for rank, (score, doc_id) in enumerate(ranked_docs[:top], start=1):\n",
        "    tweet_info = next((tweet for tweet in processed_data if tweet['DocID'] == doc_id), None)\n",
        "\n",
        "    if tweet_info:\n",
        "        # Print the rank, score, and original content of the tweet\n",
        "        print(\"\\n----------------------\\n\")\n",
        "        print(\"Rank: {} | Score: {:.4f}\".format(rank, score))\n",
        "        print(\"doc_id = {} \\ndoc_content = {}\".format(doc_id, tweet_info['Original Tweet']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijJuTvgF-nz5",
        "outputId": "5b1d7dcc-c4d2-4e20-d463-7e8454c891c2"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert your query (e.g., 'Disha Ravi'):\n",
            "\n",
            "Disha Ravi\n",
            "\n",
            "======================\n",
            "Top 20 results out of 628 ranked documents for query: Disha Ravi\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 1 | Score: 1.0000\n",
            "doc_id = doc_34928 \n",
            "doc_content = In solidarity with Disha Ravi🙏\n",
            "#Shame\n",
            "#FarmersProtest\n",
            "#IndiaBeingSilenced \n",
            "#DishaRavi https://t.co/CB2OzxbCy0\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 2 | Score: 1.0000\n",
            "doc_id = doc_36255 \n",
            "doc_content = #JusticeForDisha\n",
            "Justice For Disha Ravi \n",
            "#FarmersProtest https://t.co/juR4gPo496\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 3 | Score: 1.0000\n",
            "doc_id = doc_35814 \n",
            "doc_content = Release Disha Ravi \n",
            "\n",
            "#शहीद_जवान_शहीद_किसान\n",
            "#FarmersProtest https://t.co/KhaEkCejac\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 4 | Score: 1.0000\n",
            "doc_id = doc_33873 \n",
            "doc_content = @GretaThunberg #StandWithFarmers #FarmersProtest @PMOIndia, @nstomar RELEASE DISHA RAVI\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 5 | Score: 1.0000\n",
            "doc_id = doc_35520 \n",
            "doc_content = Release Disha Ravi .\n",
            "\n",
            "#शहीद_जवान_शहीद_किसान #DishaRavi #FarmersProtest https://t.co/43giAGdkdt\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 6 | Score: 1.0000\n",
            "doc_id = doc_36243 \n",
            "doc_content = #ReleaseDishaRavi\n",
            "Justice For Disha Ravi \n",
            "#FarmersProtest https://t.co/Q8zY9sCDxu\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 7 | Score: 1.0000\n",
            "doc_id = doc_30467 \n",
            "doc_content = #farmersprotest\n",
            "Release Disha Ravi https://t.co/QsVdv1V6dH\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 8 | Score: 1.0000\n",
            "doc_id = doc_36199 \n",
            "doc_content = Justice For Disha Ravi \n",
            "#ReleaseDishaRavi\n",
            "#FarmersProtest https://t.co/EdPfbe5iu4\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 9 | Score: 1.0000\n",
            "doc_id = doc_36249 \n",
            "doc_content = #JusticeForDisha\n",
            "Justice For Disha Ravi \n",
            "#FarmersProtest https://t.co/YB0g4AngmY\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 10 | Score: 1.0000\n",
            "doc_id = doc_32205 \n",
            "doc_content = #IndiaBeingSilenced \n",
            "#farmersprotest \n",
            "Disha ravi https://t.co/OVmvJy3d8V\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 11 | Score: 1.0000\n",
            "doc_id = doc_11995 \n",
            "doc_content = #FarmersProtest. Disha Ravi. https://t.co/VbW9rYLUIa\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 12 | Score: 1.0000\n",
            "doc_id = doc_36221 \n",
            "doc_content = #ReleaseDishaRavi\n",
            "Justice For Disha Ravi \n",
            "#FarmersProtest https://t.co/TYUNftAHIq\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 13 | Score: 1.0000\n",
            "doc_id = doc_28156 \n",
            "doc_content = #FarmersProtest                          Release Disha Ravi.. https://t.co/2Jd5dOJuDm\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 14 | Score: 1.0000\n",
            "doc_id = doc_35482 \n",
            "doc_content = #ReleaseDishaRavi \n",
            "#FarmersProtest\n",
            "Release Disha Ravi https://t.co/erHWsfvOjf\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 15 | Score: 0.8357\n",
            "doc_id = doc_9719 \n",
            "doc_content = #FarmersProtest\n",
            "#MSPLawForAllCrops \n",
            "I stand with Disha Ravi https://t.co/znHFMvSNqn\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 16 | Score: 0.8357\n",
            "doc_id = doc_28152 \n",
            "doc_content = I Stand With Disha Ravi \n",
            "#ReleaseDishaRavi \n",
            "#FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 17 | Score: 0.8357\n",
            "doc_id = doc_15603 \n",
            "doc_content = #StandWithDishaRavi\n",
            "I stand with Disha Ravi\n",
            "#FarmersProtest\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 18 | Score: 0.8357\n",
            "doc_id = doc_35524 \n",
            "doc_content = Stand with Disha Ravi #DishaRavi #FarmersProtest https://t.co/AVnJsCUc2v\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 19 | Score: 0.8357\n",
            "doc_id = doc_10256 \n",
            "doc_content = @ClaudiaWebbe We stand with Disha Ravi #kissanistan #FarmersProtest #ModiGlobalDisaster #modi_rojgar_do #kissanmazdoorektazindabaad #KisanMahapanchayat #KisanAndolan\n",
            "\n",
            "----------------------\n",
            "\n",
            "Rank: 20 | Score: 0.8296\n",
            "doc_id = doc_35672 \n",
            "doc_content = Read this article on Disha Ravi ! \n",
            "\n",
            "#FarmersProtest #शहीद_जवान_शहीद_किसान https://t.co/DAJ6RaCDQ5\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "eG-Dlwm7X_oV",
        "nrUw-B9TYFPS",
        "gW5ZEtdPYbIS",
        "wH4idut-YeyF",
        "2TBtABxYlh3C",
        "MGvgA5lelf6q"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}